<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link rel="icon" href="/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="stylesheet"
          href="https://use.fontawesome.com/releases/v5.8.1/css/all.css"
          integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf"
          crossorigin="anonymous">
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@exampledev/new.css@1.1.2/new.min.css">
    <script type="text/x-mathjax-config">
      // this should process only math inside  span with tex2jax_process class
      MathJax.Hub.Config({
          extensions: ["tex2jax.js"],
          jax: ["input/TeX", "output/HTML-CSS"],
          tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
          processEscapes: true
          },
          "HTML-CSS": { fonts: ["TeX"] }
      });
    </script>
    <script async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js">
    </script>
    <link rel="stylesheet" href="/papyri.css">
    <link rel="stylesheet" href="/pygments.css">
<style>

    header > brand {
        /*border-right: 1px solid #ccc;
          border-left: 1px solid #ccc;*/
        margin-left: 15px;
        padding: 0px;
        display: inline-block; 
        width: 67px;
    }

    brand > a {
        text-decoration: None;

    }
    brand >a> img {
            display: inline-block;
    margin: 0;
    padding: 0;
    position: relative;
    bottom: -10px;

   }
    .container {
       max-width: 800px;
       padding-left: 210px;
       padding-top: 30px;
    }
</style>
</head><body class="tex2jax_ignore">
    <header>
        <brand><a href='/'><img src='/favicon.ico'/></a></brand>
        <nav> / <a href='/' >p</a>  &nbsp;/&nbsp; 
                <div class="dropdown">
                <a href=numpy>numpy</a>&nbsp;/&nbsp;
                    <div class="dropdown-content">
                     </div>
                </div>
                <div class="dropdown">
                <a href='/p/numpy/1.22.4/api/numpy'>1.22.4</a>&nbsp;/&nbsp;
                    <div class="dropdown-content">
<a href="/p/numpy/1.22.4/api/numpy">1.22.4</a>
                    </div>
                </div>

                <div class="dropdown">
                    <a href='/p/numpy/1.22.4/api/numpy'>docs</a>&nbsp;/&nbsp;
                    <div class="dropdown-content">
                        <a href="/p/numpy/1.22.4/api/numpy">API</a>
                        <a href="/p/numpy/1.22.4/gallery">Gallery</a>
                        <a href="/p/numpy/1.22.4/examples">Examples</a>
                        <a href="/p/numpy/1.22.4/docs">Narrative</a>
                     </div>
                </div>

</nav>
    </header>
    <div class='container'>

    <div class="sidenav">
        <img src="/p/numpy/1.22.4/img/numpy_logo.png"/>
    <a href="#">numpy</a>
    <a href="#">1.22.4</a>
        <a class='external'  href="https://pypi.org/project/numpy">Pypi</a>
        <a class='external' href="https://github.com/numpy/numpy">GitHub</a>
        <a class='external' href="https://numpy.org/">Homepage</a>
    <hr/>
        <a class='external' href="https://numpy.org/doc/1.22/">Other Docs</a>
    <hr/>
    </div><!--end sidenav-->







<h1>How does the CPU dispatcher work?</h1>
               <p>NumPy dispatcher is based on multi-source compiling, which means taking a certain source and compiling it multiple times with different compiler flags and also with different <strong>C</strong> definitions that affect the code paths. This enables certain instruction-sets for each compiled object depending on the required optimizations and ends with linking the returned objects together.</p>

               <pre class='not-implemented'>
.. figure:: ../figures/opt-infra.png
    </pre>


               <p>This mechanism should support all compilers and it doesn&#39;t require any compiler-specific extension, but at the same time it adds a few steps to normal compilation that are explained as follows.</p>


<h2>1- Configuration</h2>
               <p>Configuring the required optimization by the user before starting to build the source files via the two command arguments as explained above:</p>

                          <ul>               <li>               <p>        <code class='verbatim'>--cpu-baseline</code>
: minimal set of required optimizations.</p>

</li>
               <li>               <p>        <code class='verbatim'>--cpu-dispatch</code>
: dispatched set of additional optimizations.</p>

</li>
            </ul>


<h2>2- Discovering the environment</h2>
               <p>In this part, we check the compiler and platform architecture and cache some of the intermediary results to speed up rebuilding.</p>


<h2>3- Validating the requested optimizations</h2>
               <p>By testing them against the compiler, and seeing what the compiler can support according to the requested optimizations.</p>


<h2>4- Generating the main configuration header</h2>
               <p>The generated header         <code class='verbatim'>_cpu_dispatch.h</code>
 contains all the definitions and headers of instruction-sets for the required optimizations that have been validated during the previous step.</p>

               <p>It also contains extra C definitions that are used for defining NumPy&#39;s Python-level module attributes         <code class='verbatim'>__cpu_baseline__</code>
 and         <code class='verbatim'>__cpu_dispatch__</code>
.</p>

               <p><strong>What is in this header?</strong></p>

               <p>The example header was dynamically generated by gcc on an X86 machine. The compiler supports         <code class='verbatim'>--cpu-baseline=&#34;sse sse2 sse3&#34;</code>
 and         <code class='verbatim'>--cpu-dispatch=&#34;ssse3 sse41&#34;</code>
, and the result is below.</p>

               <pre>// The header should be located at numpy/numpy/core/src/common/_cpu_dispatch.h
/**NOTE
 ** C definitions prefixed with &#34;NPY_HAVE_&#34; represent
 ** the required optimizations.
 **
 ** C definitions prefixed with &#39;NPY__CPU_TARGET_&#39; are protected and
 ** shouldn&#39;t be used by any NumPy C sources.
 */
/******* baseline features *******/
/** SSE **/
#define NPY_HAVE_SSE 1
#include &lt;xmmintrin.h&gt;
/** SSE2 **/
#define NPY_HAVE_SSE2 1
#include &lt;emmintrin.h&gt;
/** SSE3 **/
#define NPY_HAVE_SSE3 1
#include &lt;pmmintrin.h&gt;

/******* dispatch-able features *******/
#ifdef NPY__CPU_TARGET_SSSE3
  /** SSSE3 **/
  #define NPY_HAVE_SSSE3 1
  #include &lt;tmmintrin.h&gt;
#endif
#ifdef NPY__CPU_TARGET_SSE41
  /** SSE41 **/
  #define NPY_HAVE_SSE41 1
  #include &lt;smmintrin.h&gt;
#endif</pre>
               <p><strong>Baseline features</strong> are the minimal set of required optimizations configured via         <code class='verbatim'>--cpu-baseline</code>
. They have no preprocessor guards and they&#39;re always on, which means they can be used in any source.</p>

               <p>Does this mean NumPy&#39;s infrastructure passes the compiler&#39;s flags of baseline features to all sources?</p>

               <p>Definitely, yes. But the         <code class='verbatim'>dispatch-able sources &lt;dispatchable-sources&gt;</code>
 are treated differently.</p>

               <p>What if the user specifies certain <strong>baseline features</strong> during the build but at runtime the machine doesn&#39;t support even these features? Will the compiled code be called via one of these definitions, or maybe the compiler itself auto-generated/vectorized certain piece of code based on the provided command line compiler flags?</p>

               <p>During the loading of the NumPy module, there&#39;s a validation step which detects this behavior. It will raise a Python runtime error to inform the user. This is to prevent the CPU reaching an illegal instruction error causing a segfault.</p>

               <p><strong>Dispatch-able features</strong> are our dispatched set of additional optimizations that were configured via         <code class='verbatim'>--cpu-dispatch</code>
. They are not activated by default and are always guarded by other C definitions prefixed with         <code class='verbatim'>NPY__CPU_TARGET_</code>
. C definitions         <code class='verbatim'>NPY__CPU_TARGET_</code>
 are only enabled within <strong>dispatch-able sources</strong>.</p>

                          <pre class='not-implemented'>
            &lt;Unimplemented &#39;target&#39; &#39;.. _dispatchable-sources:&#39;&gt;
           </pre>


<h2>5- Dispatch-able sources and configuration statements</h2>
               <p>Dispatch-able sources are special <strong>C</strong> files that can be compiled multiple times with different compiler flags and also with different <strong>C</strong> definitions. These affect code paths to enable certain instruction-sets for each compiled object according to &#34;<strong>the
configuration statements</strong>&#34; that must be declared between a <strong>C</strong> comment\         <code class='verbatim'>(/**/)</code>
 and start with a special mark <strong>@targets</strong> at the top of each dispatch-able source. At the same time, dispatch-able sources will be treated as normal <strong>C</strong> sources if the optimization was disabled by the command argument         <code class='verbatim'>--disable-optimization</code>
 .</p>

               <p><strong>What are configuration statements?</strong></p>

               <p>Configuration statements are sort of keywords combined together to determine the required optimization for the dispatch-able source.</p>

               <p>Example:</p>

               <pre>/*@targets avx2 avx512f vsx2 vsx3 asimd asimdhp */
// C code</pre>
               <p>The keywords mainly represent the additional optimizations configured through         <code class='verbatim'>--cpu-dispatch</code>
, but it can also represent other options such as:</p>

                          <ul>               <li>               <p>Target groups: pre-configured configuration statements used for   managing the required optimizations from outside the dispatch-able source.</p>

</li>
               <li>               <p>Policies: collections of options used for changing the default   behaviors or forcing the compilers to perform certain things.</p>

</li>
               <li>               <p>&#34;baseline&#34;: a unique keyword represents the minimal optimizations   that configured through         <code class='verbatim'>--cpu-baseline</code>
</p>

</li>
            </ul>

               <p><strong>Numpy&#39;s infrastructure handles dispatch-able sources in four steps</strong>:</p>

                          <ul>               <li>               <p><strong>(A) Recognition</strong>: Just like source templates and F2PY, the   dispatch-able sources requires a special extension         <code class='verbatim'>*.dispatch.c</code>
   to mark C dispatch-able source files, and for C++           <code class='verbatim'>*.dispatch.cpp</code>
 or         <code class='verbatim'>*.dispatch.cxx</code>
   <strong>NOTE</strong>: C++ not supported yet.</p>

</li>
               <li>               <p><strong>(B) Parsing and validating</strong>: In this step, the   dispatch-able sources that had been filtered by the previous step   are parsed and validated by the configuration statements for each one   of them one by one in order to determine the required optimizations.</p>

</li>
               <li>               <p><strong>(C) Wrapping</strong>: This is the approach taken by NumPy&#39;s   infrastructure, which has proved to be sufficiently flexible in order   to compile a single source multiple times with different <strong>C</strong>   definitions and flags that affect the code paths. The process is   achieved by creating a temporary <strong>C</strong> source for each required   optimization that related to the additional optimization, which   contains the declarations of the <strong>C</strong> definitions and includes the   involved source via the <strong>C</strong> directive <strong>#include</strong>. For more   clarification take a look at the following code for AVX512F :</p>

               <pre>/*
   * this definition is used by NumPy utilities as suffixes for the
   * exported symbols
   */
  #define NPY__CPU_TARGET_CURRENT AVX512F
  /*
   * The following definitions enable
   * definitions of the dispatch-able features that are defined within the main
   * configuration header. These are definitions for the implied features.
   */
  #define NPY__CPU_TARGET_SSE
  #define NPY__CPU_TARGET_SSE2
  #define NPY__CPU_TARGET_SSE3
  #define NPY__CPU_TARGET_SSSE3
  #define NPY__CPU_TARGET_SSE41
  #define NPY__CPU_TARGET_POPCNT
  #define NPY__CPU_TARGET_SSE42
  #define NPY__CPU_TARGET_AVX
  #define NPY__CPU_TARGET_F16C
  #define NPY__CPU_TARGET_FMA3
  #define NPY__CPU_TARGET_AVX2
  #define NPY__CPU_TARGET_AVX512F
  // our dispatch-able source
  #include &#34;/the/absuolate/path/of/hello.dispatch.c&#34;</pre>
</li>
               <li>               <p><strong>(D) Dispatch-able configuration header</strong>: The infrastructure   generates a config header for each dispatch-able source, this header   mainly contains two abstract <strong>C</strong> macros used for identifying the   generated objects, so they can be used for runtime dispatching   certain symbols from the generated objects by any <strong>C</strong> source. It is   also used for forward declarations.</p>

               <p>The generated header takes the name of the dispatch-able source after   excluding the extension and replace it with         <code class='verbatim'>.h</code>
, for example   assume we have a dispatch-able source called         <code class='verbatim'>hello.dispatch.c</code>
 and   contains the following:</p>

               <pre>// hello.dispatch.c
  /*@targets baseline sse42 avx512f */
  #include &lt;stdio.h&gt;
  #include &#34;numpy/utils.h&#34; // NPY_CAT, NPY_TOSTR

  #ifndef NPY__CPU_TARGET_CURRENT
    // wrapping the dispatch-able source only happens to the additional optimizations
    // but if the keyword &#39;baseline&#39; provided within the configuration statements,
    // the infrastructure will add extra compiling for the dispatch-able source by
    // passing it as-is to the compiler without any changes.
    #define CURRENT_TARGET(X) X
    #define NPY__CPU_TARGET_CURRENT baseline // for printing only
  #else
    // since we reach to this point, that&#39;s mean we&#39;re dealing with
      // the additional optimizations, so it could be SSE42 or AVX512F
    #define CURRENT_TARGET(X) NPY_CAT(NPY_CAT(X, _), NPY__CPU_TARGET_CURRENT)
  #endif
  // Macro &#39;CURRENT_TARGET&#39; adding the current target as suffux to the exported symbols,
  // to avoid linking duplications, NumPy already has a macro called
  // &#39;NPY_CPU_DISPATCH_CURFX&#39; similar to it, located at
  // numpy/numpy/core/src/common/npy_cpu_dispatch.h
  // NOTE: we tend to not adding suffixes to the baseline exported symbols
  void CURRENT_TARGET(simd_whoami)(const char *extra_info)
  {
      printf(&#34;I&#39;m &#34; NPY_TOSTR(NPY__CPU_TARGET_CURRENT) &#34;, %s\n&#34;, extra_info);
  }</pre>
               <p>Now assume you attached <strong>hello.dispatch.c</strong> to the source tree, then   the infrastructure should generate a temporary config header called   <strong>hello.dispatch.h</strong> that can be reached by any source in the source   tree, and it should contain the following code :</p>

               <pre>#ifndef NPY__CPU_DISPATCH_EXPAND_
    // To expand the macro calls in this header
      #define NPY__CPU_DISPATCH_EXPAND_(X) X
  #endif
  // Undefining the following macros, due to the possibility of including config headers
  // multiple times within the same source and since each config header represents
  // different required optimizations according to the specified configuration
  // statements in the dispatch-able source that derived from it.
  #undef NPY__CPU_DISPATCH_BASELINE_CALL
  #undef NPY__CPU_DISPATCH_CALL
  // nothing strange here, just a normal preprocessor callback
  // enabled only if &#39;baseline&#39; specified within the configuration statements
  #define NPY__CPU_DISPATCH_BASELINE_CALL(CB, ...) \
    NPY__CPU_DISPATCH_EXPAND_(CB(__VA_ARGS__))
  // &#39;NPY__CPU_DISPATCH_CALL&#39; is an abstract macro is used for dispatching
  // the required optimizations that specified within the configuration statements.
  //
  // @param CHK, Expected a macro that can be used to detect CPU features
  // in runtime, which takes a CPU feature name without string quotes and
  // returns the testing result in a shape of boolean value.
  // NumPy already has macro called &#34;NPY_CPU_HAVE&#34;, which fits this requirement.
  //
  // @param CB, a callback macro that expected to be called multiple times depending
  // on the required optimizations, the callback should receive the following arguments:
  //  1- The pending calls of @param CHK filled up with the required CPU features,
  //     that need to be tested first in runtime before executing call belong to
  //     the compiled object.
  //  2- The required optimization name, same as in &#39;NPY__CPU_TARGET_CURRENT&#39;
  //  3- Extra arguments in the macro itself
  //
  // By default the callback calls are sorted depending on the highest interest
  // unless the policy &#34;$keep_sort&#34; was in place within the configuration statements
  // see &#34;Dive into the CPU dispatcher&#34; for more clarification.
  #define NPY__CPU_DISPATCH_CALL(CHK, CB, ...) \
    NPY__CPU_DISPATCH_EXPAND_(CB((CHK(AVX512F)), AVX512F, __VA_ARGS__)) \
    NPY__CPU_DISPATCH_EXPAND_(CB((CHK(SSE)&amp;&amp;CHK(SSE2)&amp;&amp;CHK(SSE3)&amp;&amp;CHK(SSSE3)&amp;&amp;CHK(SSE41)), SSE41, __VA_ARGS__))</pre>
               <p>An example of using the config header in light of the above:</p>

               <pre>// NOTE: The following macros are only defined for demonstration purposes only.
  // NumPy already has a collections of macros located at
  // numpy/numpy/core/src/common/npy_cpu_dispatch.h, that covers all dispatching
  // and declarations scenarios.

  #include &#34;numpy/npy_cpu_features.h&#34; // NPY_CPU_HAVE
  #include &#34;numpy/utils.h&#34; // NPY_CAT, NPY_EXPAND

  // An example for setting a macro that calls all the exported symbols at once
  // after checking if they&#39;re supported by the running machine.
  #define DISPATCH_CALL_ALL(FN, ARGS) \
      NPY__CPU_DISPATCH_CALL(NPY_CPU_HAVE, DISPATCH_CALL_ALL_CB, FN, ARGS) \
      NPY__CPU_DISPATCH_BASELINE_CALL(DISPATCH_CALL_BASELINE_ALL_CB, FN, ARGS)
  // The preprocessor callbacks.
  // The same suffixes as we define it in the dispatch-able source.
  #define DISPATCH_CALL_ALL_CB(CHECK, TARGET_NAME, FN, ARGS) \
    if (CHECK) { NPY_CAT(NPY_CAT(FN, _), TARGET_NAME) ARGS; }
  #define DISPATCH_CALL_BASELINE_ALL_CB(FN, ARGS) \
    FN NPY_EXPAND(ARGS);

  // An example for setting a macro that calls the exported symbols of highest
  // interest optimization, after checking if they&#39;re supported by the running machine.
  #define DISPATCH_CALL_HIGH(FN, ARGS) \
    if (0) {} \
      NPY__CPU_DISPATCH_CALL(NPY_CPU_HAVE, DISPATCH_CALL_HIGH_CB, FN, ARGS) \
      NPY__CPU_DISPATCH_BASELINE_CALL(DISPATCH_CALL_BASELINE_HIGH_CB, FN, ARGS)
  // The preprocessor callbacks
  // The same suffixes as we define it in the dispatch-able source.
  #define DISPATCH_CALL_HIGH_CB(CHECK, TARGET_NAME, FN, ARGS) \
    else if (CHECK) { NPY_CAT(NPY_CAT(FN, _), TARGET_NAME) ARGS; }
  #define DISPATCH_CALL_BASELINE_HIGH_CB(FN, ARGS) \
    else { FN NPY_EXPAND(ARGS); }

  // NumPy has a macro called &#39;NPY_CPU_DISPATCH_DECLARE&#39; can be used
  // for forward declarations any kind of prototypes based on
  // &#39;NPY__CPU_DISPATCH_CALL&#39; and &#39;NPY__CPU_DISPATCH_BASELINE_CALL&#39;.
  // However in this example, we just handle it manually.
  void simd_whoami(const char *extra_info);
  void simd_whoami_AVX512F(const char *extra_info);
  void simd_whoami_SSE41(const char *extra_info);

  void trigger_me(void)
  {
      // bring the auto-generated config header
      // which contains config macros &#39;NPY__CPU_DISPATCH_CALL&#39; and
      // &#39;NPY__CPU_DISPATCH_BASELINE_CALL&#39;.
      // it is highly recommended to include the config header before executing
    // the dispatching macros in case if there&#39;s another header in the scope.
      #include &#34;hello.dispatch.h&#34;
      DISPATCH_CALL_ALL(simd_whoami, (&#34;all&#34;))
      DISPATCH_CALL_HIGH(simd_whoami, (&#34;the highest interest&#34;))
      // An example of including multiple config headers in the same source
      // #include &#34;hello2.dispatch.h&#34;
      // DISPATCH_CALL_HIGH(another_function, (&#34;the highest interest&#34;))
  }</pre>
</li>
            </ul>


<h3 id="section-Examples">Examples</h3>
         See :
    


<h3>Local connectivity graph</h3>
<p>Hover to see nodes names; edges to Self not shown, Caped at 50 nodes.</p>

<p> Using a canvas is more power efficient and can get hundred of nodes ; but does not allow hyperlinks; , arrows
or text (beyond on hover) </p> 
<canvas class='graph' width="800" height="500"></canvas>
<p> SVG is more flexible but power hungry; and does not scale well to 50 + nodes. </p> 

<svg class='graph' width="600" height="500"></svg>

<p>All aboves nodes referred to, (or are referred from) current nodes; Edges from Self to other have been omitted
(or all nodes would be connected to the central node "self" which is not useful). Nodes are colored by the library
they belong to, and scaled with the number of references pointing them</p>

<hr>

    GitHub : <a class='external' href='https://github.com/numpy/numpy/blob/v1.22.3/None#LNone'>None#None</a>
<br/>

type: None <br/>
Commit: <br/>

        <script src="https://d3js.org/d3.v4.min.js"></script>
    <script src="https://d3js.org/d3-selection-multi.v1.js"></script>
    <style type="text/css">
        .node {};
        .link { stroke: #999; stroke-opacity: .6; stroke-width: 1px; };
    </style>
<script>
    window._data_graph = {};
</script>
<script type="text/javascript" src='/graph_canvas.js'></script>
<script type="text/javascript" src='/graph_svg.js'></script>


</div>
</body>
</html>