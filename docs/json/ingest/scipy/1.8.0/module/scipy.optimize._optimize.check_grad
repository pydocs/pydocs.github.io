Ùª­jAttributesÙ¯‚€öpExtended SummaryÙ¯‚€ögMethodsÙ¯‚€öeNotesÙ¯‚€öpOther ParametersÙ¯‚€öjParametersÙ¯‚‡Ù°ƒdfuncxcallable ``func(x0, *args)``Ù¹‚Ù§x+Function whose derivative is to be checked.€Ù°ƒdgradxcallable ``grad(x0, *args)``Ù¹‚ƒÙ§lGradient of Ù¢„dfuncÙ „ööelocaldfuncelocalõÙ§a.€Ù°ƒbx0gndarrayÙ¹‚…Ù§pPoints to check Ù¢„dgradÙ „escipye1.8.0fmodulex<scipy.optimize._differentiable_functions.ScalarFunction.gradfmoduleõÙ§x8 against forward difference approximation of grad using Ù¢„dfuncÙ „ööelocaldfuncelocalõÙ§a.€Ù°ƒdargsp\*args, optionalÙ¹‚…Ù§xExtra arguments passed to Ù¢„dfuncÙ „ööelocaldfuncelocalõÙ§e and Ù¢„dgradÙ „escipye1.8.0fmodulex<scipy.optimize._differentiable_functions.ScalarFunction.gradfmoduleõÙ§a.€Ù°ƒgepsilonofloat, optionalÙ¹‚ƒÙ§xGStep size used for the finite difference approximation. It defaults to Ù¡xsqrt(np.finfo(float).eps)Ù§x", which is approximately 1.49e-08.€Ù°ƒidirectionmstr, optionalÙ¹‚‹Ù§jIf set to Ù¡h'random'Ù§x9, then gradients along a random vector are used to check Ù¢„dgradÙ „escipye1.8.0fmodulex<scipy.optimize._differentiable_functions.ScalarFunction.gradfmoduleõÙ§x0 against forward difference approximation using Ù¢„dfuncÙ „ööelocaldfuncelocalõÙ§s. By default it is Ù¡e'all'Ù§xK, in which case, all the one hot direction vectors are considered to check Ù¢„dgradÙ „escipye1.8.0fmodulex<scipy.optimize._differentiable_functions.ScalarFunction.gradfmoduleõÙ§a.€Ù°ƒdseedx%{None, int, `numpy.random.Generator`,‚Ù·x%`numpy.random.RandomState`}, optionalÙ¹‚˜Ù§cIf Ù¢„dseedÙ „escipye1.8.0fmodulexscipy.linalg.interpolative.seedfmoduleõÙ§m is None (or Ù£ƒinp.randomööÙ§g), the Ù¢„xnumpy.random.RandomStateÙ „enumpya*capixnumpy.random.mtrand.RandomStatefmoduleõÙ§w singleton is used. If Ù¢„dseedÙ „escipye1.8.0fmodulexscipy.linalg.interpolative.seedfmoduleõÙ§r is an int, a new Ù¡kRandomStateÙ§x instance is used, seeded with Ù¢„dseedÙ „escipye1.8.0fmodulexscipy.linalg.interpolative.seedfmoduleõÙ§e. If Ù¢„dseedÙ „escipye1.8.0fmodulexscipy.linalg.interpolative.seedfmoduleõÙ§n is already a Ù¡iGeneratorÙ§d or Ù¡kRandomStateÙ§x. instance then that instance is used. Specify Ù¢„dseedÙ „escipye1.8.0fmodulexscipy.linalg.interpolative.seedfmoduleõÙ§x§ for reproducing the return value from this function. The random numbers generated with this seed affect the random vector along which gradients are computed to check Ù¡dgradÙ§l. Note that Ù¢„dseedÙ „escipye1.8.0fmodulexscipy.linalg.interpolative.seedfmoduleõÙ§s is only used when Ù¢„idirectionÙ „ööelocalidirectionelocalõÙ§t argument is set to Ù£ƒh'random'ööÙ§a.€öfRaisesÙ¯‚€öhReceivesÙ¯‚€ögReturnsÙ¯‚Ù°ƒcerrefloatÙ¹‚‡Ù§xSThe square root of the sum of squares (i.e., the 2-norm) of the difference between Ù¡ograd(x0, *args)Ù§x, and the finite difference approximation of Ù¢„dgradÙ „escipye1.8.0fmodulex<scipy.optimize._differentiable_functions.ScalarFunction.gradfmoduleõÙ§x using func at the points Ù¢„bx0Ù „ööelocalbx0elocalõÙ§a.€ögSummaryÙ¯‚Ù¹‚Ù§xCheck the correctness of a gradient function by comparing it against a (forward) finite-difference approximation of the gradient.€öhWarningsÙ¯‚€öeWarnsÙ¯‚€öfYieldsÙ¯‚€ö…gSummaryjParametersgReturnshSee AlsohExamplesx/scipy/optimize/_optimize.py×r<class 'function'>x/scipy.signal._filter_design.optimize.check_gradÙ¯‚‚Ù´ƒ˜_Ù±‚akcdefÙ±‚`a Ù±‚bnfdfuncÙ±‚`a(Ù±‚`axÙ±‚`a)Ù±‚`a:Ù±‚`a
Ù±‚`d    Ù±‚akÙ¢„freturnÙ „escipye1.8.0fmodulex(scipy.integrate._ode.ode.get_return_codefmoduleõÙ±‚`a Ù±‚`axÙ±‚`a[Ù±‚bmia0Ù±‚`a]Ù±‚aoa*Ù±‚aoa*Ù±‚bmia2Ù±‚`a Ù±‚aoa-Ù±‚`a Ù±‚bmfc0.5Ù±‚`a Ù±‚aoa*Ù±‚`a Ù±‚`axÙ±‚`a[Ù±‚bmia1Ù±‚`a]Ù±‚aoa*Ù±‚aoa*Ù±‚bmia3Ù±‚`a
Ù±‚akcdefÙ±‚`a Ù±‚bnfÙ¢„dgradÙ „escipye1.8.0fmodulex<scipy.optimize._differentiable_functions.ScalarFunction.gradfmoduleõÙ±‚`a(Ù±‚`axÙ±‚`a)Ù±‚`a:Ù±‚`a
Ù±‚`d    Ù±‚akÙ¢„freturnÙ „escipye1.8.0fmodulex(scipy.integrate._ode.ode.get_return_codefmoduleõÙ±‚`a Ù±‚`a[Ù±‚bmia2Ù±‚`a Ù±‚aoa*Ù±‚`a Ù±‚`axÙ±‚`a[Ù±‚bmia0Ù±‚`a]Ù±‚`a,Ù±‚`a Ù±‚aoa-Ù±‚bmfc1.5Ù±‚`a Ù±‚aoa*Ù±‚`a Ù±‚`axÙ±‚`a[Ù±‚bmia1Ù±‚`a]Ù±‚aoa*Ù±‚aoa*Ù±‚bmia2Ù±‚`a]Ù±‚`a
Ù±‚bkndfromÙ±‚`a Ù±‚bnnÙ¢„escipyÙ „escipye1.8.0fmoduleescipyfmoduleõÙ±‚bnna.Ù±‚bnnÙ¢„hoptimizeÙ „escipye1.8.0fmodulenscipy.optimizefmoduleõÙ±‚`a Ù±‚bknfimportÙ±‚`a Ù±‚`Ù¢„jcheck_gradÙ „escipye1.8.0fmodulex#scipy.optimize._optimize.check_gradfmoduleõÙ±‚`a
Ù±‚`Ù¢„jcheck_gradÙ „escipye1.8.0fmodulex#scipy.optimize._optimize.check_gradfmoduleõÙ±‚`a(Ù±‚`dfuncÙ±‚`a,Ù±‚`a Ù±‚`Ù¢„dgradÙ „escipye1.8.0fmodulex<scipy.optimize._differentiable_functions.ScalarFunction.gradfmoduleõÙ±‚`a,Ù±‚`a Ù±‚`a[Ù±‚bmfc1.5Ù±‚`a,Ù±‚`a Ù±‚aoa-Ù±‚bmfc1.5Ù±‚`a]Ù±‚`a)x"2.9802322387695312e-08  # may varyfexecedÙ´ƒ˜)Ù±‚`Ù¢„crngÙ „enumpyf1.22.3fmodulex!numpy.random._generator.GeneratorfmoduleõÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„bnpÙ „enumpyf1.22.3fmoduleenumpyfmoduleõÙ±‚aoa.Ù±‚`Ù¢„frandomÙ „enumpyf1.22.3fmodulelnumpy.randomfmoduleõÙ±‚aoa.Ù±‚`Ù¢„kdefault_rngÙ „enumpyf1.22.3fmodulex#numpy.random._generator.default_rngfmoduleõÙ±‚`a(Ù±‚`a)Ù±‚`a
Ù±‚`Ù¢„jcheck_gradÙ „escipye1.8.0fmodulex#scipy.optimize._optimize.check_gradfmoduleõÙ±‚`a(Ù±‚`dfuncÙ±‚`a,Ù±‚`a Ù±‚`Ù¢„dgradÙ „escipye1.8.0fmodulex<scipy.optimize._differentiable_functions.ScalarFunction.gradfmoduleõÙ±‚`a,Ù±‚`a Ù±‚`a[Ù±‚bmfc1.5Ù±‚`a,Ù±‚`a Ù±‚aoa-Ù±‚bmfc1.5Ù±‚`a]Ù±‚`a,Ù±‚`a
Ù±‚`l            Ù±‚`idirectionÙ±‚aoa=Ù±‚bs1a'Ù±‚bs1Ù¢„frandomÙ „escipye1.8.0fmodulexscipy.sparse._construct.randomfmoduleõÙ±‚bs1a'Ù±‚`a,Ù±‚`a Ù±‚`Ù¢„dseedÙ „escipye1.8.0fmodulexscipy.linalg.interpolative.seedfmoduleõÙ±‚aoa=Ù±‚`Ù¢„crngÙ „enumpyf1.22.3fmodulex!numpy.random._generator.GeneratorfmoduleõÙ±‚`a)v2.9802322387695312e-08fexecedöÙ¼ƒÙ»ƒmapprox_fprimex&scipy.optimize._optimize.approx_fprimeõ€öe1.8.0Ù«x]check_grad(func, grad, x0, *args, epsilon=1.4901161193847656e-08, direction='all', seed=None)öx#scipy.optimize._optimize.check_grad€