Ùª­jAttributesÙ¯‚€öpExtended SummaryÙ¯‚ƒÙ¹‚Ù§x*Find a zero of the scalar-valued function Ù¢„dfuncÙ „ööelocaldfuncelocalõÙ§x& given a nearby scalar starting point Ù¢„bx0Ù „ööelocalbx0elocalõÙ§x6. The Newton-Raphson method is used if the derivative Ù¢„ffprimeÙ „escipye1.8.0fmodulex-scipy.optimize._root_scalar.MemoizeDer.fprimefmoduleõÙ§d of Ù¢„dfuncÙ „ööelocaldfuncelocalõÙ§xR is provided, otherwise the secant method is used. If the second order derivative Ù¢„gfprime2Ù „escipye1.8.0fmodulex.scipy.optimize._root_scalar.MemoizeDer.fprime2fmoduleõÙ§d of Ù¢„dfuncÙ „ööelocaldfuncelocalõÙ§x0 is also provided, then Halley's method is used.€Ù¹‚Ù§cIf Ù¢„bx0Ù „ööelocalbx0elocalõÙ§x( is a sequence with more than one item, Ù¢„fnewtonÙ „escipye1.8.0fmodulexscipy.optimize._zeros_py.newtonfmoduleõÙ§xR returns an array: the zeros of the function from each (scalar) starting point in Ù¢„bx0Ù „ööelocalbx0elocalõÙ§p. In this case, Ù¢„dfuncÙ „ööelocaldfuncelocalõÙ§x^ must be vectorized to return a sequence or array of the same shape as its first argument. If Ù¢„ffprimeÙ „escipye1.8.0fmodulex-scipy.optimize._root_scalar.MemoizeDer.fprimefmoduleõÙ§b (Ù¢„gfprime2Ù „escipye1.8.0fmodulex.scipy.optimize._root_scalar.MemoizeDer.fprime2fmoduleõÙ§xl) is given, then its return must also have the same shape: each element is the first (second) derivative of Ù¢„dfuncÙ „ööelocaldfuncelocalõÙ§xS with respect to its only variable evaluated at each element of its first argument.€Ù¹‚„Ù¢„fnewtonÙ „escipye1.8.0fmodulexscipy.optimize._zeros_py.newtonfmoduleõÙ§xw is for finding roots of a scalar-valued functions of a single variable. For problems involving several variables, see Ù¢„drootÙ „escipye1.8.0fmodulexscipy.optimize._root.rootfmoduleõÙ§a.€ögMethodsÙ¯‚€öeNotesÙ¯‚ƒÙ¹‚Ù§yøThe convergence rate of the Newton-Raphson method is quadratic, the Halley method is cubic, and the secant method is sub-quadratic. This means that if the function is well-behaved the actual error in the estimated zero after the nth iteration is approximately the square (cube for Halley) of the error after the (n-1)th step. However, the stopping criterion used here is the step size and there is no guarantee that a zero has been found. Consequently, the result should be verified. Safer algorithms are brentq, brenth, ridder, and bisect, but they all require that the root first be bracketed in an interval where the function changes sign. The brentq algorithm is recommended for general use in one dimensional problems when such an interval has been found.€Ù¹‚ƒÙ§eWhen Ù¢„fnewtonÙ „escipye1.8.0fmodulexscipy.optimize._zeros_py.newtonfmoduleõÙ§xL is used with arrays, it is best suited for the following types of problems:€ÙÈƒÙ¹‚ƒÙ§uThe initial guesses, Ù£ƒbx0ööÙ§x8, are all relatively the same distance from   the roots.€Ù¹‚ƒÙ§x$Some or all of the extra arguments, Ù£ƒdargsööÙ§xO, are also arrays so that a   class of similar problems can be solved together.€Ù¹‚ƒÙ§x!The size of the initial guesses, Ù£ƒbx0ööÙ§xh, is larger than O(100) elements.   Otherwise, a naive loop may perform as well or better than a vector.€öpOther ParametersÙ¯‚€öjParametersÙ¯‚‹Ù°ƒdfunchcallableÙ¹‚‡Ù§xZThe function whose zero is wanted. It must be a function of a single variable of the form Ù¡mf(x,a,b,c...)Ù§h, where Ù¡ha,b,c...Ù§x/ are extra arguments that can be passed in the Ù¢„dargsÙ „ööelocaldargselocalõÙ§k parameter.€Ù°ƒbx0xfloat, sequence, or ndarrayÙ¹‚ƒÙ§xcAn initial estimate of the zero that should be somewhere near the actual zero. If not scalar, then Ù¢„dfuncÙ „ööelocaldfuncelocalõÙ§x[ must be vectorized and return a sequence or array of the same shape as its first argument.€Ù°ƒffprimercallable, optionalÙ¹‚Ù§xvThe derivative of the function when available and convenient. If it is None (default), then the secant method is used.€Ù°ƒdargsotuple, optionalÙ¹‚Ù§x0Extra arguments to be used in the function call.€Ù°ƒctolofloat, optionalÙ¹‚‰Ù§x*The allowable error of the zero value. If Ù¢„dfuncÙ „ööelocaldfuncelocalõÙ§x is complex-valued, a larger Ù¢„ctolÙ „ööelocalctolelocalõÙ§x8 is recommended as both the real and imaginary parts of Ù£ƒaxööÙ§o contribute to Ù¡h|x - x0|Ù§a.€Ù°ƒgmaxitermint, optionalÙ¹‚Ù§xMaximum number of iterations.€Ù°ƒgfprime2rcallable, optionalÙ¹‚Ù§xÑThe second order derivative of the function when available and convenient. If it is None (default), then the normal Newton-Raphson or the secant method is used. If it is not None, then Halley's method is used.€Ù°ƒbx1ofloat, optionalÙ¹‚ƒÙ§xTAnother estimate of the zero that should be somewhere near the actual zero. Used if Ù¢„ffprimeÙ „escipye1.8.0fmodulex-scipy.optimize._root_scalar.MemoizeDer.fprimefmoduleõÙ§q is not provided.€Ù°ƒdrtolofloat, optionalÙ¹‚Ù§x%Tolerance (relative) for termination.€Ù°ƒkfull_outputnbool, optionalÙ¹‚‘Ù§cIf Ù¢„kfull_outputÙ „ööelocalkfull_outputelocalõÙ§x7 is False (default), the root is returned. If True and Ù¢„bx0Ù „ööelocalbx0elocalõÙ§x  is scalar, the return value is Ù¡f(x, r)Ù§h, where Ù¡axÙ§q is the root and Ù¡arÙ§f is a Ù¢„kRootResultsÙ „escipye1.8.0fmodulex$scipy.optimize._zeros_py.RootResultsfmoduleõÙ§u object. If True and Ù¢„bx0Ù „ööelocalbx0elocalõÙ§x$ is non-scalar, the return value is Ù¡x(x, converged,
zero_der)Ù§x# (see Returns section for details).€Ù°ƒddispnbool, optionalÙ¹‚†Ù§xÊIf True, raise a RuntimeError if the algorithm didn't converge, with the error message containing the number of iterations and current function value. Otherwise, the convergence status is recorded in a Ù¢„kRootResultsÙ „escipye1.8.0fmodulex$scipy.optimize._zeros_py.RootResultsfmoduleõÙ§x return object. Ignored if Ù¢„bx0Ù „ööelocalbx0elocalõÙ§p is not scalar. Ù¨Ù§xwNote: this has little to do with displaying, however,
the `disp` keyword cannot be renamed for backwards compatibility.€öfRaisesÙ¯‚€öhReceivesÙ¯‚€ögReturnsÙ¯‚„Ù°ƒdrootxfloat, sequence, or ndarrayÙ¹‚Ù§x*Estimated location where function is zero.€Ù°ƒarw`RootResults`, optionalÙ¹‚‡Ù§kPresent if Ù¡pfull_output=TrueÙ§e and Ù¢„bx0Ù „ööelocalbx0elocalõÙ§xP is scalar. Object containing information about the convergence. In particular, Ù¡kr.convergedÙ§x" is True if the routine converged.€Ù°ƒiconvergedxndarray of bool, optionalÙ¹‚…Ù§kPresent if Ù¡pfull_output=TrueÙ§e and Ù¢„bx0Ù „ööelocalbx0elocalõÙ§xV is non-scalar. For vector functions, indicates which elements converged successfully.€Ù°ƒhzero_derxndarray of bool, optionalÙ¹‚…Ù§kPresent if Ù¡pfull_output=TrueÙ§e and Ù¢„bx0Ù „ööelocalbx0elocalõÙ§xU is non-scalar. For vector functions, indicates which elements had a zero derivative.€ögSummaryÙ¯‚Ù¹‚Ù§xbFind a zero of a real or complex function using the Newton-Raphson (or secant or Halley's) method.€öhWarningsÙ¯‚€öeWarnsÙ¯‚€öfYieldsÙ¯‚€ö‡gSummarypExtended SummaryjParametersgReturnshSee AlsoeNoteshExamplesx/scipy/optimize/_zeros_py.py^r<class 'function'>x+scipy.signal._filter_design.optimize.newtonÙ¯‚Ù´ƒ‘Ù±‚bkndfromÙ±‚`a Ù±‚bnnÙ¢„escipyÙ „escipye1.8.0fmoduleescipyfmoduleõÙ±‚`a Ù±‚bknfimportÙ±‚`a Ù±‚`Ù¢„hoptimizeÙ „escipye1.8.0fmodulenscipy.optimizefmoduleõÙ±‚`a
Ù±‚bknfimportÙ±‚`a Ù±‚bnnÙ¢„jmatplotlibÙ „jmatplotlibe3.5.1fmodulejmatplotlibfmoduleõÙ±‚bnna.Ù±‚bnnÙ¢„fpyplotÙ „jmatplotlibe3.5.1fmoduleqmatplotlib.pyplotfmoduleõÙ±‚`a Ù±‚akbasÙ±‚`a Ù±‚bnnÙ¢„cpltÙ „jmatplotlibe3.5.1fmoduleqmatplotlib.pyplotfmoduleõ`fexecedÙ´ƒ—Ù±‚akcdefÙ±‚`a Ù±‚bnfÙ¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ±‚`a(Ù±‚`axÙ±‚`a)Ù±‚`a:Ù±‚`a
Ù±‚`d    Ù±‚akÙ¢„freturnÙ „escipye1.8.0fmodulex(scipy.integrate._ode.ode.get_return_codefmoduleõÙ±‚`a Ù±‚`a(Ù±‚`axÙ±‚aoa*Ù±‚aoa*Ù±‚bmia3Ù±‚`a Ù±‚aoa-Ù±‚`a Ù±‚bmia1Ù±‚`a)Ù±‚`b  Ù±‚bc1x# only one real root at x = 1`fexecedÙ¹‚‚Ù¡ffprimeÙ§x( is not provided, use the secant method:€Ù´ƒÙ±‚`drootÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„hoptimizeÙ „escipye1.8.0fmodulenscipy.optimizefmoduleõÙ±‚aoa.Ù±‚`Ù¢„fnewtonÙ „escipye1.8.0fmodulexscipy.optimize._zeros_py.newtonfmoduleõÙ±‚`a(Ù±‚`Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ±‚`a,Ù±‚`a Ù±‚bmfc1.5Ù±‚`a)Ù±‚`a
Ù±‚`drootr1.0000000000000016fexecedÙ´ƒ˜Ù±‚`drootÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„hoptimizeÙ „escipye1.8.0fmodulenscipy.optimizefmoduleõÙ±‚aoa.Ù±‚`Ù¢„fnewtonÙ „escipye1.8.0fmodulexscipy.optimize._zeros_py.newtonfmoduleõÙ±‚`a(Ù±‚`Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ±‚`a,Ù±‚`a Ù±‚bmfc1.5Ù±‚`a,Ù±‚`a Ù±‚`Ù¢„gfprime2Ù „escipye1.8.0fmodulex.scipy.optimize._root_scalar.MemoizeDer.fprime2fmoduleõÙ±‚aoa=Ù±‚akflambdaÙ±‚`a Ù±‚`axÙ±‚`a:Ù±‚`a Ù±‚bmia6Ù±‚`a Ù±‚aoa*Ù±‚`a Ù±‚`axÙ±‚`a)Ù±‚`a
Ù±‚`drootr1.0000000000000016fexecedÙ¹‚ƒÙ§eOnly Ù¡ffprimeÙ§x, is provided, use the Newton-Raphson method:€Ù´ƒ˜ Ù±‚`drootÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„hoptimizeÙ „escipye1.8.0fmodulenscipy.optimizefmoduleõÙ±‚aoa.Ù±‚`Ù¢„fnewtonÙ „escipye1.8.0fmodulexscipy.optimize._zeros_py.newtonfmoduleõÙ±‚`a(Ù±‚`Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ±‚`a,Ù±‚`a Ù±‚bmfc1.5Ù±‚`a,Ù±‚`a Ù±‚`Ù¢„ffprimeÙ „escipye1.8.0fmodulex-scipy.optimize._root_scalar.MemoizeDer.fprimefmoduleõÙ±‚aoa=Ù±‚akflambdaÙ±‚`a Ù±‚`axÙ±‚`a:Ù±‚`a Ù±‚bmia3Ù±‚`a Ù±‚aoa*Ù±‚`a Ù±‚`axÙ±‚aoa*Ù±‚aoa*Ù±‚bmia2Ù±‚`a)Ù±‚`a
Ù±‚`drootc1.0fexecedÙ¹‚…Ù§eBoth Ù¡gfprime2Ù§e and Ù¡ffprimeÙ§x# are provided, use Halley's method:€Ù´ƒ˜/Ù±‚`drootÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„hoptimizeÙ „escipye1.8.0fmodulenscipy.optimizefmoduleõÙ±‚aoa.Ù±‚`Ù¢„fnewtonÙ „escipye1.8.0fmodulexscipy.optimize._zeros_py.newtonfmoduleõÙ±‚`a(Ù±‚`Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ±‚`a,Ù±‚`a Ù±‚bmfc1.5Ù±‚`a,Ù±‚`a Ù±‚`Ù¢„ffprimeÙ „escipye1.8.0fmodulex-scipy.optimize._root_scalar.MemoizeDer.fprimefmoduleõÙ±‚aoa=Ù±‚akflambdaÙ±‚`a Ù±‚`axÙ±‚`a:Ù±‚`a Ù±‚bmia3Ù±‚`a Ù±‚aoa*Ù±‚`a Ù±‚`axÙ±‚aoa*Ù±‚aoa*Ù±‚bmia2Ù±‚`a,Ù±‚`a
Ù±‚`w                       Ù±‚`Ù¢„gfprime2Ù „escipye1.8.0fmodulex.scipy.optimize._root_scalar.MemoizeDer.fprime2fmoduleõÙ±‚aoa=Ù±‚akflambdaÙ±‚`a Ù±‚`axÙ±‚`a:Ù±‚`a Ù±‚bmia6Ù±‚`a Ù±‚aoa*Ù±‚`a Ù±‚`axÙ±‚`a)Ù±‚`a
Ù±‚`drootc1.0fexecedÙ¹‚Ù§xWhen we want to find zeros for a set of related starting values and/or function parameters, we can provide both of those as an array of inputs:€Ù´ƒ˜pÙ±‚`Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚akflambdaÙ±‚`a Ù±‚`axÙ±‚`a,Ù±‚`a Ù±‚`aaÙ±‚`a:Ù±‚`a Ù±‚`axÙ±‚aoa*Ù±‚aoa*Ù±‚bmia3Ù±‚`a Ù±‚aoa-Ù±‚`a Ù±‚`aaÙ±‚`a
Ù±‚`dfderÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚akflambdaÙ±‚`a Ù±‚`axÙ±‚`a,Ù±‚`a Ù±‚`aaÙ±‚`a:Ù±‚`a Ù±‚bmia3Ù±‚`a Ù±‚aoa*Ù±‚`a Ù±‚`axÙ±‚aoa*Ù±‚aoa*Ù±‚bmia2Ù±‚`a
Ù±‚`Ù¢„crngÙ „enumpyf1.22.3fmodulex!numpy.random._generator.GeneratorfmoduleõÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„bnpÙ „enumpyf1.22.3fmoduleenumpyfmoduleõÙ±‚aoa.Ù±‚`Ù¢„frandomÙ „enumpyf1.22.3fmodulelnumpy.randomfmoduleõÙ±‚aoa.Ù±‚`Ù¢„kdefault_rngÙ „enumpyf1.22.3fmodulex#numpy.random._generator.default_rngfmoduleõÙ±‚`a(Ù±‚`a)Ù±‚`a
Ù±‚`axÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„crngÙ „enumpyf1.22.3fmodulex!numpy.random._generator.GeneratorfmoduleõÙ±‚aoa.Ù±‚`ostandard_normalÙ±‚`a(Ù±‚bmic100Ù±‚`a)Ù±‚`a
Ù±‚`Ù¢„aaÙ „enumpyf1.22.3fmodulemnumpy.ndarrayfmoduleõÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„bnpÙ „enumpyf1.22.3fmoduleenumpyfmoduleõÙ±‚aoa.Ù±‚`Ù¢„farangeÙ „enumpyf1.22.3fmodulelnumpy.arangefmoduleõÙ±‚`a(Ù±‚aoa-Ù±‚bmib50Ù±‚`a,Ù±‚`a Ù±‚bmib50Ù±‚`a)Ù±‚`a
Ù±‚`gvec_resÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„hoptimizeÙ „escipye1.8.0fmodulenscipy.optimizefmoduleõÙ±‚aoa.Ù±‚`Ù¢„fnewtonÙ „escipye1.8.0fmodulexscipy.optimize._zeros_py.newtonfmoduleõÙ±‚`a(Ù±‚`Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ±‚`a,Ù±‚`a Ù±‚`axÙ±‚`a,Ù±‚`a Ù±‚`Ù¢„ffprimeÙ „escipye1.8.0fmodulex-scipy.optimize._root_scalar.MemoizeDer.fprimefmoduleõÙ±‚aoa=Ù±‚`dfderÙ±‚`a,Ù±‚`a Ù±‚`dargsÙ±‚aoa=Ù±‚`a(Ù±‚`Ù¢„aaÙ „enumpyf1.22.3fmodulemnumpy.ndarrayfmoduleõÙ±‚`a,Ù±‚`a Ù±‚`a)Ù±‚`a,Ù±‚`a Ù±‚`gmaxiterÙ±‚aoa=Ù±‚bmic200Ù±‚`a)`fexecedÙ¹‚ƒÙ§x9The above is the equivalent of solving for each value in Ù¡f(x, a)Ù§x' separately in a for-loop, just faster:€Ù´ƒ˜>Ù±‚`hloop_resÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`a[Ù±‚`Ù¢„hoptimizeÙ „escipye1.8.0fmodulenscipy.optimizefmoduleõÙ±‚aoa.Ù±‚`Ù¢„fnewtonÙ „escipye1.8.0fmodulexscipy.optimize._zeros_py.newtonfmoduleõÙ±‚`a(Ù±‚`Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ±‚`a,Ù±‚`a Ù±‚`bx0Ù±‚`a,Ù±‚`a Ù±‚`Ù¢„ffprimeÙ „escipye1.8.0fmodulex-scipy.optimize._root_scalar.MemoizeDer.fprimefmoduleõÙ±‚aoa=Ù±‚`dfderÙ±‚`a,Ù±‚`a Ù±‚`dargsÙ±‚aoa=Ù±‚`a(Ù±‚`ba0Ù±‚`a,Ù±‚`a)Ù±‚`a,Ù±‚`a
Ù±‚`x                            Ù±‚`gmaxiterÙ±‚aoa=Ù±‚bmic200Ù±‚`a)Ù±‚`a
Ù±‚`l            Ù±‚akcforÙ±‚`a Ù±‚`bx0Ù±‚`a,Ù±‚`a Ù±‚`ba0Ù±‚`a Ù±‚bowbinÙ±‚`a Ù±‚bnbczipÙ±‚`a(Ù±‚`axÙ±‚`a,Ù±‚`a Ù±‚`Ù¢„aaÙ „enumpyf1.22.3fmodulemnumpy.ndarrayfmoduleõÙ±‚`a)Ù±‚`a]Ù±‚`a
Ù±‚`Ù¢„bnpÙ „enumpyf1.22.3fmoduleenumpyfmoduleõÙ±‚aoa.Ù±‚`Ù¢„hallcloseÙ „enumpyf1.22.3fmodulennumpy.allclosefmoduleõÙ±‚`a(Ù±‚`gvec_resÙ±‚`a,Ù±‚`a Ù±‚`hloop_resÙ±‚`a)dTruefexecedÙ¹‚ƒÙ§x)Plot the results found for all values of Ù¡aaÙ§a:€Ù´ƒ˜]Ù±‚`qanalytical_resultÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„bnpÙ „enumpyf1.22.3fmoduleenumpyfmoduleõÙ±‚aoa.Ù±‚`Ù¢„dsignÙ „enumpyf1.22.3fmoduleknumpy.ufuncfmoduleõÙ±‚`a(Ù±‚`Ù¢„aaÙ „enumpyf1.22.3fmodulemnumpy.ndarrayfmoduleõÙ±‚`a)Ù±‚`a Ù±‚aoa*Ù±‚`a Ù±‚`Ù¢„bnpÙ „enumpyf1.22.3fmoduleenumpyfmoduleõÙ±‚aoa.Ù±‚`Ù¢„cabsÙ „enumpyf1.22.3fmoduleknumpy.ufuncfmoduleõÙ±‚`a(Ù±‚`Ù¢„aaÙ „enumpyf1.22.3fmodulemnumpy.ndarrayfmoduleõÙ±‚`a)Ù±‚aoa*Ù±‚aoa*Ù±‚`a(Ù±‚bmia1Ù±‚aoa/Ù±‚bmia3Ù±‚`a)Ù±‚`a
Ù±‚`cfigÙ±‚`a,Ù±‚`a Ù±‚`baxÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„cpltÙ „jmatplotlibe3.5.1fmoduleqmatplotlib.pyplotfmoduleõÙ±‚aoa.Ù±‚`Ù¢„hsubplotsÙ „jmatplotlibe3.5.1fmodulexmatplotlib.pyplot.subplotsfmoduleõÙ±‚`a(Ù±‚`a)Ù±‚`a
Ù±‚`Ù¢„baxÙ „jmatplotlibe3.5.1fmodulex%matplotlib.axes._subplots.AxesSubplotfmoduleõÙ±‚aoa.Ù±‚`Ù¢„dplotÙ „jmatplotlibe3.5.1fmodulexmatplotlib.axes._axes.Axes.plotfmoduleõÙ±‚`a(Ù±‚`Ù¢„aaÙ „enumpyf1.22.3fmodulemnumpy.ndarrayfmoduleõÙ±‚`a,Ù±‚`a Ù±‚`qanalytical_resultÙ±‚`a,Ù±‚`a Ù±‚bs1a'Ù±‚bs1aoÙ±‚bs1a'Ù±‚`a)Ù±‚`a
Ù±‚`Ù¢„baxÙ „jmatplotlibe3.5.1fmodulex%matplotlib.axes._subplots.AxesSubplotfmoduleõÙ±‚aoa.Ù±‚`Ù¢„dplotÙ „jmatplotlibe3.5.1fmodulexmatplotlib.axes._axes.Axes.plotfmoduleõÙ±‚`a(Ù±‚`Ù¢„aaÙ „enumpyf1.22.3fmodulemnumpy.ndarrayfmoduleõÙ±‚`a,Ù±‚`a Ù±‚`gvec_resÙ±‚`a,Ù±‚`a Ù±‚bs1a'Ù±‚bs1a.Ù±‚bs1a'Ù±‚`a)Ù±‚`a
Ù±‚`Ù¢„baxÙ „jmatplotlibe3.5.1fmodulex%matplotlib.axes._subplots.AxesSubplotfmoduleõÙ±‚aoa.Ù±‚`Ù¢„jset_xlabelÙ „jmatplotlibe3.5.1fmodulex*matplotlib.axes._base._AxesBase.set_xlabelfmoduleõÙ±‚`a(Ù±‚bs1a'Ù±‚bs1c$a$Ù±‚bs1a'Ù±‚`a)Ù±‚`a
Ù±‚`Ù¢„baxÙ „jmatplotlibe3.5.1fmodulex%matplotlib.axes._subplots.AxesSubplotfmoduleõÙ±‚aoa.Ù±‚`Ù¢„jset_ylabelÙ „jmatplotlibe3.5.1fmodulex*matplotlib.axes._base._AxesBase.set_ylabelfmoduleõÙ±‚`a(Ù±‚bs1a'Ù±‚bs1u$x$ where $f(x, a)=0$Ù±‚bs1a'Ù±‚`a)Ù±‚`a
Ù±‚`Ù¢„cpltÙ „jmatplotlibe3.5.1fmoduleqmatplotlib.pyplotfmoduleõÙ±‚aoa.Ù±‚`Ù¢„dshowÙ „jmatplotlibe3.5.1fmodulevmatplotlib.pyplot.showfmoduleõÙ±‚`a(Ù±‚`a)`fexecedÙ¸x)fig-scipy.optimize._zeros_py.newton-0.pngö‚Ù¼ƒÙ»ƒdrootööÙ¹‚Ù§xAinterface to root solvers for multi-input, multi-output functions€öÙ¼ƒÙ»ƒkroot_scalarx'scipy.optimize._root_scalar.root_scalarõÙ¹‚Ù§x.interface to root solvers for scalar functions€öe1.8.0Ù«xnewton(func, x0, fprime=None, args=(), tol=1.48e-08, maxiter=50, fprime2=None, x1=None, rtol=0.0, full_output=False, disp=True)öxscipy.optimize._zeros_py.newton€