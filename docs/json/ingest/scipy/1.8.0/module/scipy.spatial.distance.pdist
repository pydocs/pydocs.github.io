Ùª­jAttributesÙ¯‚€öpExtended SummaryÙ¯‚Ù¹‚Ù§x)See Notes for common calling conventions.€ögMethodsÙ¯‚€öeNotesÙ¯‚˜Ù¹‚ƒÙ§dSee Ù¡jsquareformÙ§x† for information on how to calculate the index of this entry or to convert the condensed distance matrix to a redundant square matrix.€Ù¹‚Ù§x-The following are common calling conventions.€ÙÇ‚Ù¹‚Ù¡xY = pdist(X, 'euclidean')€Ù¹‚Ù§xÁComputes the distance between m points using Euclidean distance    (2-norm) as the distance metric between the points. The points    are arranged as m n-dimensional row vectors in the matrix X.€ÙÇ‚Ù¹‚Ù¡xY = pdist(X, 'minkowski', p=2.)€Ù¹‚‰Ù§x7Computes the distances using the Minkowski distance    Ù¥i\|u-v\|_pÙ§b (Ù¥apÙ§m-norm) where Ù¥ep > 0Ù§x. (note    that this is only a quasi-metric if Ù¥i0 < p < 1Ù§b).€ÙÇ‚Ù¹‚Ù¡xY = pdist(X, 'cityblock')€Ù¹‚Ù§xDComputes the city block or Manhattan distance between the    points.€ÙÇ„Ù¹‚Ù¡x"Y = pdist(X, 'seuclidean', V=None)€Ù¹‚…Ù§xkComputes the standardized Euclidean distance. The standardized    Euclidean distance between two n-vectors Ù¡auÙ§e and Ù¡avÙ§c is€Ù¤x+\sqrt { \sum { ( u_i - v_i)^2 / V [ x_i]}} Ù¹‚Ù§x—V is the variance vector; V[i] is the variance computed over all    the i'th components of the points.  If not passed, it is    automatically computed.€ÙÇ‚Ù¹‚Ù¡xY = pdist(X, 'sqeuclidean')€Ù¹‚ƒÙ§x(Computes the squared Euclidean distance Ù¥k\|u-v\|_2^2Ù§x between    the vectors.€ÙÇ„Ù¹‚Ù¡vY = pdist(X, 'cosine')€Ù¹‚Ù§x5Computes the cosine distance between vectors u and v,€Ù¤x01 - \frac { u \cdot v} { { \|u\|}_2 { \|v\|}_2} Ù¹‚‹Ù§fwhere Ù¥g\|*\|_2Ù§x is the 2-norm of its argument Ù¡a*Ù§i, and    Ù¥iu \cdot vÙ§w is the dot product of Ù¡auÙ§e and Ù¡avÙ§a.€ÙÇ„Ù¹‚Ù¡xY = pdist(X, 'correlation')€Ù¹‚Ù§xBComputes the correlation distance between vectors u and v. This is€Ù¤xn1 - \frac { ( u - \bar { u}) \cdot ( v - \bar { v})} { { \| ( u - \bar { u})\|}_2 { \| ( v - \bar { v})\|}_2} Ù¹‚‰Ù§fwhere Ù¥g\bar{v}Ù§x1 is the mean of the elements of vector v,    and Ù¥ix \cdot yÙ§w is the dot product of Ù¥axÙ§e and Ù¥ayÙ§a.€ÙÇ‚Ù¹‚Ù¡wY = pdist(X, 'hamming')€Ù¹‚‡Ù§xnComputes the normalized Hamming distance, or the proportion of    those vector elements between two n-vectors Ù¡auÙ§e and Ù¡avÙ§x/    which disagree. To save memory, the matrix Ù¡aXÙ§x can be of type    boolean.€ÙÇ‚Ù¹‚Ù¡wY = pdist(X, 'jaccard')€Ù¹‚‰Ù§xHComputes the Jaccard distance between the points. Given two    vectors, Ù¡auÙ§e and Ù¡avÙ§x>, the Jaccard distance is the    proportion of those elements Ù¡du[i]Ù§e and Ù¡dv[i]Ù§r that    disagree.€ÙÇ„Ù¹‚Ù¡xY = pdist(X, 'jensenshannon')€Ù¹‚…Ù§xhComputes the Jensen-Shannon distance between two probability arrays.     Given two probability vectors, Ù¥apÙ§e and Ù¥aqÙ§x$, the     Jensen-Shannon distance is€Ù¤x?\sqrt { \frac { D ( p \parallel m) + D ( q \parallel m)} { 2}} Ù¹‚‰Ù§fwhere Ù¥amÙ§x is the pointwise mean of Ù¥apÙ§e and Ù¥aqÙ§i     and Ù¥aDÙ§x$ is the Kullback-Leibler divergence.€ÙÇƒÙ¹‚Ù¡xY = pdist(X, 'chebyshev')€Ù¹‚…Ù§xeComputes the Chebyshev distance between the points. The     Chebyshev distance between two n-vectors Ù¡auÙ§e and Ù¡avÙ§xs is the     maximum norm-1 distance between their respective elements. More     precisely, the distance is given by€Ù¤x!d ( u,v) = \max_i { |u_i - v_i|} ÙÇƒÙ¹‚Ù¡xY = pdist(X, 'canberra')€Ù¹‚…Ù§x`Computes the Canberra distance between the points. The     Canberra distance between two points Ù¡auÙ§e and Ù¡avÙ§c is€Ù¤x6d ( u,v) = \sum_i \frac { |u_i - v_i|} { |u_i|+|v_i|} ÙÇƒÙ¹‚Ù¡xY = pdist(X, 'braycurtis')€Ù¹‚…Ù§xfComputes the Bray-Curtis distance between the points. The     Bray-Curtis distance between two points Ù¡auÙ§e and Ù¡avÙ§c is€Ù¤xAd ( u,v) = \frac { \sum_i { |u_i - v_i|}} { \sum_i { |u_i+v_i|}} ÙÇ‚Ù¹‚Ù¡x$Y = pdist(X, 'mahalanobis', VI=None)€Ù¹‚Ù§xfComputes the Mahalanobis distance between the points. The     Mahalanobis distance between two points Ù¡auÙ§e and Ù¡avÙ§h is     Ù¥x\sqrt{(u-v)(1/V)(u-v)^T}Ù§g where Ù¥e(1/V)Ù§f (the Ù¡bVIÙ§x-     variable) is the inverse covariance. If Ù¡bVIÙ§r is not None,     Ù¡bVIÙ§x/ will be used as the inverse covariance matrix.€ÙÇ‚Ù¹‚Ù¡tY = pdist(X, 'yule')€Ù¹‚Ù§xfComputes the Yule distance between each pair of boolean     vectors. (see yule function documentation)€ÙÇ‚Ù¹‚Ù¡xY = pdist(X, 'matching')€Ù¹‚Ù§vSynonym for 'hamming'.€ÙÇ‚Ù¹‚Ù¡tY = pdist(X, 'dice')€Ù¹‚Ù§xfComputes the Dice distance between each pair of boolean     vectors. (see dice function documentation)€ÙÇ‚Ù¹‚Ù¡xY = pdist(X, 'kulsinski')€Ù¹‚Ù§xpComputes the Kulsinski distance between each pair of     boolean vectors. (see kulsinski function documentation)€ÙÇ‚Ù¹‚Ù¡xY = pdist(X, 'rogerstanimoto')€Ù¹‚Ù§x{Computes the Rogers-Tanimoto distance between each pair of     boolean vectors. (see rogerstanimoto function documentation)€ÙÇ‚Ù¹‚Ù¡xY = pdist(X, 'russellrao')€Ù¹‚Ù§xsComputes the Russell-Rao distance between each pair of     boolean vectors. (see russellrao function documentation)€ÙÇ‚Ù¹‚Ù¡xY = pdist(X, 'sokalmichener')€Ù¹‚Ù§xyComputes the Sokal-Michener distance between each pair of     boolean vectors. (see sokalmichener function documentation)€ÙÇ‚Ù¹‚Ù¡xY = pdist(X, 'sokalsneath')€Ù¹‚Ù§xuComputes the Sokal-Sneath distance between each pair of     boolean vectors. (see sokalsneath function documentation)€ÙÇ‚Ù¹‚Ù¡xY = pdist(X, 'kulczynski1')€Ù¹‚Ù§xuComputes the Kulczynski 1 distance between each pair of     boolean vectors. (see kulczynski1 function documentation)€ÙÇ‡Ù¹‚Ù¡oY = pdist(X, f)€Ù¹‚Ù§xÊComputes the distance between all pairs of vectors in X     using the user supplied 2-arity function f. For example,     Euclidean distance between the vectors could be computed     as follows::        €ÙÀx5dm = pdist(X, lambda u, v: np.sqrt(((u-v)**2).sum()))Ù¹‚Ù§xƒNote that you should avoid passing a reference to one of     the distance functions defined in this library. For example,::        €ÙÀxdm = pdist(X, sokalsneath)Ù¹‚ƒÙ§xwould calculate the pair-wise distances between the vectors in     X using the Python function sokalsneath. This would result in     sokalsneath being called Ù¥m{n \choose 2}Ù§x times, which     is inefficient. Instead, the optimized C version is more     efficient, and we call it using the following syntax.::        €ÙÀxdm = pdist(X, 'sokalsneath')öpOther ParametersÙ¯‚€öjParametersÙ¯‚ƒÙ°ƒaXjarray_likeÙ¹‚Ù§xEAn m by n array of m original observations in an n-dimensional space.€Ù°ƒfmetricxstr or function, optionalÙ¹‚Ù§yjThe distance metric to use. The distance function can be 'braycurtis', 'canberra', 'chebyshev', 'cityblock', 'correlation', 'cosine', 'dice', 'euclidean', 'hamming', 'jaccard', 'jensenshannon', 'kulsinski', 'kulczynski1', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule'.€Ù°ƒh**kwargsndict, optional‚Ù¹‚ƒÙ§sExtra arguments to Ù¢„fmetricÙ „ööelocalfmetricelocalõÙ§xJ: refer to each metric documentation for a list of all possible arguments.€Ù¹‚Ù§xSome possible arguments:€öfRaisesÙ¯‚€öhReceivesÙ¯‚€ögReturnsÙ¯‚Ù°ƒaYgndarrayÙ¹‚‹Ù§x0Returns a condensed distance matrix Y. For each Ù¥aiÙ§e and Ù¥ajÙ§h (where Ù¥ei<j<mÙ§x=),where m is the number of original observations. The metric Ù¡tdist(u=X[i], v=X[j])Ù§x! is computed and stored in entry Ù¡x$m
* i + j - ((i + 2) * (i + 1)) // 2Ù§a.€ögSummaryÙ¯‚Ù¹‚Ù§x?Pairwise distances between observations in n-dimensional space.€öhWarningsÙ¯‚€öeWarnsÙ¯‚€öfYieldsÙ¯‚€ö†gSummarypExtended SummaryjParametersgReturnshSee AlsoeNotesx/scipy/spatial/distance.py©r<class 'function'>x+scipy.signal._ltisys.interpolate._rbf.pdistÙ¯‚€öÙ¼ƒÙ»ƒjsquareformx!scipy.spatial.distance.squareformõÙ¹‚Ù§xJconverts between condensed distance matrices and square distance matrices.€öe1.8.0Ù«x3pdist(X, metric='euclidean', *, out=None, **kwargs)öxscipy.spatial.distance.pdist€