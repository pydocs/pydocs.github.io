Ùª­jAttributesÙ¯‚€öpExtended SummaryÙ¯‚‚Ù¹‚‰Ù§x]Implements the Algorithm 748 method of Alefeld, Potro and Shi to find a zero of the function Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ§q on the interval Ù£ƒg[a , b]ööÙ§h, where Ù£ƒdf(a)ööÙ§e and Ù£ƒdf(b)ööÙ§x must have opposite signs.€Ù¹‚Ù§xYIt uses a mixture of inverse cubic interpolation and "Newton-quadratic" steps. [APS1995].€ögMethodsÙ¯‚€öeNotesÙ¯‚‚Ù¹‚„Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ§x( must be continuous. Algorithm 748 with Ù¡ck=2Ù§yS is asymptotically the most efficient algorithm known for finding roots of a four times continuously differentiable function. In contrast with Brent's algorithm, which may only decrease the length of the enclosing bracket on the last step, Algorithm 748 decreases it each iteration with the same asymptotic efficiency as it finds the root.€Ù¹‚Ù§x6For easy statement of efficiency indices, assume that Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ§x& has 4 continuouous deriviatives. For Ù¡ck=1Ù§x, the convergence order is at least 2.7, and with about asymptotically 2 function evaluations per iteration, the efficiency index is approximately 1.65. For Ù¡ck=2Ù§x‡, the order is about 4.6 with asymptotically 3 function evaluations per iteration, and the efficiency index 1.66. For higher values of Ù¢„akÙ „ööelocalakelocalõÙ§x2, the efficiency index approaches the kth root of Ù¡f(3k-2)Ù§h, hence Ù¡ck=1Ù§d or Ù¡ck=2Ù§x are usually appropriate.€öpOther ParametersÙ¯‚€öjParametersÙ¯‚ŠÙ°ƒafhfunctionÙ¹‚‡Ù§x1Python function returning a scalar. The function Ù¥afÙ§x must be continuous, and Ù¥df(a)Ù§e and Ù¥df(b)Ù§u have opposite signs.€Ù°ƒaagscalar,Ù¹‚Ù§x%lower boundary of the search interval€Ù°ƒabgscalar,Ù¹‚Ù§x%upper boundary of the search interval€Ù°ƒdargsotuple, optionalÙ¹‚‡Ù§x,containing extra arguments for the function Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ§b. Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ§n is called by Ù¡kf(x, *args)Ù§a.€Ù°ƒakmint, optionalÙ¹‚ƒÙ§x@The number of Newton quadratic steps to perform each iteration. Ù¡dk>=1Ù§a.€Ù°ƒdxtolpscalar, optionalÙ¹‚‡Ù§rThe computed root Ù¡bx0Ù§n will satisfy Ù¡x(np.allclose(x, x0,
atol=xtol, rtol=rtol)Ù§h, where Ù¡axÙ§x6 is the exact root. The parameter must be nonnegative.€Ù°ƒdrtolpscalar, optionalÙ¹‚‡Ù§rThe computed root Ù¡bx0Ù§n will satisfy Ù¡x(np.allclose(x, x0,
atol=xtol, rtol=rtol)Ù§h, where Ù¡axÙ§s is the exact root.€Ù°ƒgmaxitermint, optionalÙ¹‚ƒÙ§x"If convergence is not achieved in Ù¢„gmaxiterÙ „ööelocalgmaxiterelocalõÙ§x. iterations, an error is raised. Must be >= 0.€Ù°ƒkfull_outputnbool, optionalÙ¹‚Ù§cIf Ù¢„kfull_outputÙ „ööelocalkfull_outputelocalõÙ§x$ is False, the root is returned. If Ù¢„kfull_outputÙ „ööelocalkfull_outputelocalõÙ§x is True, the return value is Ù¡f(x, r)Ù§h, where Ù£ƒaxööÙ§r is the root, and Ù¢„arÙ „ööelocalarelocalõÙ§f is a Ù¢„kRootResultsÙ „escipye1.8.0fmodulex$scipy.optimize._zeros_py.RootResultsfmoduleõÙ§h object.€Ù°ƒddispnbool, optionalÙ¹‚ƒÙ§xsIf True, raise RuntimeError if the algorithm didn't converge. Otherwise, the convergence status is recorded in the Ù¢„kRootResultsÙ „escipye1.8.0fmodulex$scipy.optimize._zeros_py.RootResultsfmoduleõÙ§o return object.€öfRaisesÙ¯‚€öhReceivesÙ¯‚€ögReturnsÙ¯‚‚Ù°ƒbx0efloatÙ¹‚‚Ù§tApproximate Zero of Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõ€Ù°ƒarx1`RootResults` (present if ``full_output = True``)Ù¹‚ƒÙ§xDObject containing information about the convergence. In particular, Ù¡kr.convergedÙ§x" is True if the routine converged.€ögSummaryÙ¯‚Ù¹‚Ù§x,Find a zero using TOMS Algorithm 748 method.€öhWarningsÙ¯‚€öeWarnsÙ¯‚€öfYieldsÙ¯‚€öˆgSummarypExtended SummaryjParametersgReturnshSee AlsoeNotesjReferenceshExamplesx/scipy/optimize/_zeros_py.pyàr<class 'function'>x,scipy.signal._filter_design.optimize.toms748Ù¯‚ƒÙ´ƒ—Ù±‚akcdefÙ±‚`a Ù±‚bnfÙ¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ±‚`a(Ù±‚`axÙ±‚`a)Ù±‚`a:Ù±‚`a
Ù±‚`d    Ù±‚akÙ¢„freturnÙ „escipye1.8.0fmodulex(scipy.integrate._ode.ode.get_return_codefmoduleõÙ±‚`a Ù±‚`a(Ù±‚`axÙ±‚aoa*Ù±‚aoa*Ù±‚bmia3Ù±‚`a Ù±‚aoa-Ù±‚`a Ù±‚bmia1Ù±‚`a)Ù±‚`b  Ù±‚bc1x# only one real root at x = 1`fexecedÙ´ƒ˜"Ù±‚bkndfromÙ±‚`a Ù±‚bnnÙ¢„escipyÙ „escipye1.8.0fmoduleescipyfmoduleõÙ±‚`a Ù±‚bknfimportÙ±‚`a Ù±‚`Ù¢„hoptimizeÙ „escipye1.8.0fmodulenscipy.optimizefmoduleõÙ±‚`a
Ù±‚`drootÙ±‚`a,Ù±‚`a Ù±‚`gresultsÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„hoptimizeÙ „escipye1.8.0fmodulenscipy.optimizefmoduleõÙ±‚aoa.Ù±‚`Ù¢„gtoms748Ù „escipye1.8.0fmodulex scipy.optimize._zeros_py.toms748fmoduleõÙ±‚`a(Ù±‚`Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ±‚`a,Ù±‚`a Ù±‚bmia0Ù±‚`a,Ù±‚`a Ù±‚bmia2Ù±‚`a,Ù±‚`a Ù±‚`kfull_outputÙ±‚aoa=Ù±‚bkcdTrueÙ±‚`a)Ù±‚`a
Ù±‚`drootc1.0fexecedÙ´ƒÙ±‚`gresultsxn      converged: True
           flag: 'converged'
 function_calls: 11
     iterations: 5
           root: 1.0fexecedö†Ù¼ƒÙ»ƒfbisectxscipy.optimize._zeros_py.bisectõ€öÙ¼ƒÙ»ƒfbrenthöö€öÙ¼ƒÙ»ƒfbrentqöö€öÙ¼ƒÙ»ƒffsolvex!scipy.optimize._minpack_py.fsolveõÙ¹‚Ù§xfind zeroes in N dimensions.€öÙ¼ƒÙ»ƒfnewtonxscipy.optimize._zeros_py.newtonõ€öÙ¼ƒÙ»ƒfridderöö€öe1.8.0Ù«xqtoms748(f, a, b, args=(), k=1, xtol=2e-12, rtol=8.881784197001252e-16, maxiter=100, full_output=False, disp=True)öx scipy.optimize._zeros_py.toms748€