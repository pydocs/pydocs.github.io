Ùª­jAttributesÙ¯‚€öpExtended SummaryÙ¯‚€ögMethodsÙ¯‚€öeNotesÙ¯‚€öpOther ParametersÙ¯‚€öjParametersÙ¯‚”Ù°ƒdfunchcallableÙ¹‚‡Ù§x=The objective function to be minimized.  Must be in the form Ù¡kf(x, *args)Ù§h, where Ù¡axÙ§x0 is the argument in the form of a 1-D array and Ù¡dargsÙ§xZ is a  tuple of any additional fixed parameters needed to completely specify the function.€Ù°ƒfboundstsequence or `Bounds`Ù¹‚Ù§xPBounds for variables.  There are two ways to specify the bounds: 1. Instance of Ù¢„fBoundsÙ „escipye1.8.0fmodulex"scipy.optimize._constraints.BoundsfmoduleõÙ§k class. 2. Ù¡j(min, max)Ù§x pairs for each element in Ù¡axÙ§xL, defining the finite lower and upper bounds for the optimizing argument of Ù¢„dfuncÙ „ööelocaldfuncelocalõÙ§x. It is required to have Ù¡ulen(bounds) == len(x)Ù§b. Ù¡klen(bounds)Ù§x2 is used to determine the number of parameters in Ù¡axÙ§a.€Ù°ƒdargsotuple, optionalÙ¹‚Ù§xTAny additional fixed parameters needed to completely specify the objective function.€Ù°ƒhstrategymstr, optionalƒÙ¹‚Ù§x=The differential evolution strategy to use. Should be one of:€Ù·Œl- 'best1bin'l- 'best1exp'l- 'rand1exp'r- 'randtobest1exp'u- 'currenttobest1exp'l- 'best2exp'l- 'rand2exp'r- 'randtobest1bin'u- 'currenttobest1bin'l- 'best2bin'l- 'rand2bin'l- 'rand1bin'Ù¹‚Ù§xThe default is 'best1bin'€Ù°ƒgmaxitermint, optionalÙ¹‚‚Ù§x’The maximum number of generations over which the entire population is evolved. The maximum number of function evaluations (with no polishing) is: Ù¡x (maxiter + 1) * popsize * len(x)€Ù°ƒgpopsizemint, optionalÙ¹‚‰Ù§xGA multiplier for setting the total population size. The population has Ù¡ppopsize * len(x)Ù§xV individuals. This keyword is overridden if an initial population is supplied via the Ù¢„dinitÙ „ööelocaldinitelocalõÙ§u keyword. When using Ù¡linit='sobol'Ù§x@ the population size is calculated as the next power of 2 after Ù¡ppopsize * len(x)Ù§a.€Ù°ƒctolofloat, optionalÙ¹‚‡Ù§x;Relative tolerance for convergence, the solving stops when Ù¡x@np.std(pop) <= atol + tol * np.abs(np.mean(population_energies))Ù§l, where and Ù¢„datolÙ „escipye1.8.0fmodulex/scipy.sparse.linalg._isolve.iterative._get_atolfmoduleõÙ§e and Ù¢„ctolÙ „ööelocalctolelocalõÙ§x6 are the absolute and relative tolerance respectively.€Ù°ƒhmutationx&float or tuple(float, float), optionalÙ¹‚ƒÙ§xºThe mutation constant. In the literature this is also known as differential weight, being denoted by F. If specified as a float it should be in the range [0, 2]. If specified as a tuple Ù¡j(min, max)Ù§yD dithering is employed. Dithering randomly changes the mutation constant on a generation by generation basis. The mutation constant for that generation is taken from U[min, max). Dithering can help speed convergence significantly. Increasing the mutation constant increases the search radius, but will slow down convergence.€Ù°ƒmrecombinationofloat, optionalÙ¹‚Ù§yThe recombination constant, should be in the range [0, 1]. In the literature this is also known as the crossover probability, being denoted by CR. Increasing this value allows a larger number of mutants to progress into the next generation, but at the risk of population stability.€Ù°ƒdseedx%{None, int, `numpy.random.Generator`,‚Ù·x%`numpy.random.RandomState`}, optionalÙ¹‚•Ù§cIf Ù¢„dseedÙ „escipye1.8.0fmodulexscipy.linalg.interpolative.seedfmoduleõÙ§m is None (or Ù£ƒinp.randomööÙ§g), the Ù¢„xnumpy.random.RandomStateÙ „enumpya*capixnumpy.random.mtrand.RandomStatefmoduleõÙ§w singleton is used. If Ù¢„dseedÙ „escipye1.8.0fmodulexscipy.linalg.interpolative.seedfmoduleõÙ§r is an int, a new Ù¡kRandomStateÙ§x instance is used, seeded with Ù¢„dseedÙ „escipye1.8.0fmodulexscipy.linalg.interpolative.seedfmoduleõÙ§e. If Ù¢„dseedÙ „escipye1.8.0fmodulexscipy.linalg.interpolative.seedfmoduleõÙ§n is already a Ù¡iGeneratorÙ§d or Ù¡kRandomStateÙ§x. instance then that instance is used. Specify Ù¢„dseedÙ „escipye1.8.0fmodulexscipy.linalg.interpolative.seedfmoduleõÙ§x for repeatable minimizations.€Ù°ƒddispnbool, optionalÙ¹‚ƒÙ§uPrints the evaluated Ù¢„dfuncÙ „ööelocaldfuncelocalõÙ§t at every iteration.€Ù°ƒhcallbackx3callable, `callback(xk, convergence=val)`, optionalÙ¹‚‹Ù§x7A function to follow the progress of the minimization. Ù¡bxkÙ§x is the current value of Ù¡bx0Ù§b. Ù¡cvalÙ§xE represents the fractional value of the population convergence. When Ù¡cvalÙ§x= is greater than one the function halts. If callback returns Ù¡dTrueÙ§xG, then the minimization is halted (any polishing is still carried out).€Ù°ƒfpolishnbool, optionalÙ¹‚‡Ù§xIf True (default), then Ù¢„wscipy.optimize.minimizeÙ „escipya*capix!scipy.optimize._minimize.minimizefmoduleõÙ§j with the Ù£ƒhL-BFGS-BööÙ§x¡ method is used to polish the best population member at the end, which can improve the minimization slightly. If a constrained problem is being studied then the Ù£ƒltrust-conströöÙ§x method is used instead.€Ù°ƒfmaxfunmint, optionalÙ¹‚ƒÙ§x]Set the maximum number of function evaluations. However, it probably makes more sense to set Ù¢„gmaxiterÙ „ööelocalgmaxiterelocalõÙ§i instead.€Ù°ƒdinitxstr or array-like, optional…Ù¹‚Ù§xOSpecify which type of population initialization is performed. Should be one of:€Ù·ˆr- 'latinhypercube'i- 'sobol'j- 'halton'j- 'random'x@- array specifying the initial population. The array should havexA  shape ``(M, len(x))``, where M is the total population size andx%  len(x) is the number of parameters.x+  `init` is clipped to `bounds` before use.Ù¹‚Ù§xvThe default is 'latinhypercube'. Latin Hypercube sampling tries to maximize coverage of the available parameter space.€Ù¹‚…Ù§x¼'sobol' and 'halton' are superior alternatives and maximize even more the parameter space. 'sobol' will enforce an initial population size which is calculated as the next power of 2 after Ù¡ppopsize * len(x)Ù§x@. 'halton' has no requirements but is a bit less efficient. See Ù¢„oscipy.stats.qmcÙ „escipya*capioscipy.stats.qmcfmoduleõÙ§r for more details.€Ù¹‚Ù§ya'random' initializes the population randomly - this has the drawback that clustering can occur, preventing the whole of parameter space being covered. Use of an array to specify a population could be used, for example, to create a tight bunch of initial guesses in an location where the solution is known to exist, thereby reducing time for convergence.€Ù°ƒdatolofloat, optionalÙ¹‚‡Ù§x;Absolute tolerance for convergence, the solving stops when Ù¡x@np.std(pop) <= atol + tol * np.abs(np.mean(population_energies))Ù§l, where and Ù¢„datolÙ „escipye1.8.0fmodulex/scipy.sparse.linalg._isolve.iterative._get_atolfmoduleõÙ§e and Ù¢„ctolÙ „ööelocalctolelocalõÙ§x6 are the absolute and relative tolerance respectively.€Ù°ƒhupdatingx#{'immediate', 'deferred'}, optionalÙ¹‚‰Ù§cIf Ù£ƒiimmediateööÙ§xÌ the best solution vector is continuously updated within a single generation. This can lead to faster convergence as trial vectors can take advantage of continuous improvements in the best solution. With Ù£ƒhdeferredööÙ§x? the best solution vector is updated once per generation. Only Ù£ƒhdeferredööÙ§x- is compatible with parallelization, and the Ù¢„gworkersÙ „ööelocalgworkerselocalõÙ§x# keyword can over-ride this option.€Ù°ƒgworkersx"int or map-like callable, optionalÙ¹‚•Ù§cIf Ù¢„gworkersÙ „ööelocalgworkerselocalõÙ§x- is an int the population is subdivided into Ù¢„gworkersÙ „ööelocalgworkerselocalõÙ§x* sections and evaluated in parallel (uses Ù£ƒx&multiprocessing.Pool <multiprocessing>ööÙ§j). Supply Ù£ƒb-1ööÙ§x^ to use all cores available to the Process. Alternatively supply a map-like callable, such as Ù£ƒxmultiprocessing.Pool.mapööÙ§xN for evaluating the population in parallel. This evaluation is carried out as Ù¡wworkers(func, iterable)Ù§x . This option will override the Ù¢„hupdatingÙ „ööelocalhupdatingelocalõÙ§l keyword to Ù£ƒsupdating='deferred'ööÙ§d if Ù£ƒlworkers != 1ööÙ§p. Requires that Ù¢„dfuncÙ „ööelocaldfuncelocalõÙ§o be pickleable.€Ù°ƒkconstraintsx/{NonLinearConstraint, LinearConstraint, Bounds}Ù¹‚ƒÙ§x?Constraints on the solver, over and above those applied by the Ù¢„fboundsÙ „ööelocalfboundselocalõÙ§x$ kwd. Uses the approach by Lampinen.€Ù°ƒbx0xNone or array-like, optionalÙ¹‚ƒÙ§x§Provides an initial guess to the minimization. Once the population has been initialized this vector replaces the first (best) member. This replacement is done even if Ù¢„dinitÙ „ööelocaldinitelocalõÙ§x  is given an initial population.€öfRaisesÙ¯‚€öhReceivesÙ¯‚€ögReturnsÙ¯‚€ögSummaryÙ¯‚Ù¹‚Ù§x7This class implements the differential evolution solver€öhWarningsÙ¯‚€öeWarnsÙ¯‚€öfYieldsÙ¯‚€ö‚gSummaryjParametersx)/scipy/optimize/_differentialevolution.pyNn<class 'type'>xWscipy.signal._filter_design.optimize._differentialevolution.DifferentialEvolutionSolverÙ¯‚€ö€e1.8.0Ù«ööxAscipy.optimize._differentialevolution.DifferentialEvolutionSolver€