Ùª­jAttributesÙ¯‚€öpExtended SummaryÙ¯‚€ögMethodsÙ¯‚€öeNotesÙ¯‚Ù¹‚Ù§x·This algorithm implements the inexact Newton method, with backtracking or full line searches. Several Jacobian approximations are available, including Krylov and Quasi-Newton methods.€öpOther ParametersÙ¯‚€öjParametersÙ¯‚Ù°ƒaFpfunction(x) -> fÙ¹‚Ù§xIFunction whose root to find; should take and return an array-like object.€Ù°ƒcxinjarray_likeÙ¹‚Ù§xInitial guess for the solution€Ù°ƒhjacobianhJacobian‚Ù¹‚…Ù§xA Jacobian approximation: Ù¢„hJacobianÙ „escipye1.8.0fmodulexscipy.optimize._nonlin.JacobianfmoduleõÙ§x object or something that Ù¢„jasjacobianÙ „escipye1.8.0fmodulex!scipy.optimize._nonlin.asjacobianfmoduleõÙ§xn can transform to one. Alternatively, a string specifying which of the builtin Jacobian approximations to use:€Ù·‚x$krylov, broyden1, broyden2, andersonx)diagbroyden, linearmixing, excitingmixingÙ°ƒditermint, optionalÙ¹‚Ù§x`Number of iterations to make. If omitted (default), make as many as required to meet tolerances.€Ù°ƒgverbosenbool, optionalÙ¹‚Ù§x*Print status to stdout on every iteration.€Ù°ƒgmaxitermint, optionalÙ¹‚ƒÙ§xNMaximum number of iterations to make. If more are needed to meet convergence, Ù¢„mNoConvergenceÙ „escipye1.8.0fmodulex$scipy.optimize._nonlin.NoConvergencefmoduleõÙ§k is raised.€Ù°ƒef_tolofloat, optionalÙ¹‚Ù§xOAbsolute tolerance (in max-norm) for the residual. If omitted, default is 6e-6.€Ù°ƒff_rtolofloat, optionalÙ¹‚Ù§x:Relative tolerance for the residual. If omitted, not used.€Ù°ƒex_tolofloat, optionalÙ¹‚Ù§x±Absolute minimum step size, as determined from the Jacobian approximation. If the step size is smaller than this, optimization is terminated as successful. If omitted, not used.€Ù°ƒfx_rtolofloat, optionalÙ¹‚Ù§x1Relative minimum step size. If omitted, not used.€Ù°ƒhtol_normx$function(vector) -> scalar, optionalÙ¹‚Ù§x>Norm to use in convergence check. Default is the maximum norm.€Ù°ƒkline_searchx-{None, 'armijo' (default), 'wolfe'}, optionalÙ¹‚Ù§x‰Which type of a line search to use to determine the step size in the direction given by the Jacobian approximation. Defaults to 'armijo'.€Ù°ƒhcallbackrfunction, optionalÙ¹‚‡Ù§x?Optional callback function. It is called on every iteration as Ù¡ncallback(x, f)Ù§g where Ù£ƒaxööÙ§x is the current solution and Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ§x the corresponding residual.€öfRaisesÙ¯‚ƒÙ°ƒ`mNoConvergenceÙ¹‚Ù§xWhen a solution was not found.€Ù°ƒkfull_outputdboolÙ¹‚ƒÙ§xIf true, returns a dictionary Ù£ƒdinfoööÙ§x$ containing convergence information.€Ù°ƒoraise_exceptiondboolÙ¹‚ƒÙ§kIf True, a Ù¢„mNoConvergenceÙ „escipye1.8.0fmodulex$scipy.optimize._nonlin.NoConvergencefmoduleõÙ§x, exception is raise if no solution is found.€öhReceivesÙ¯‚€ögReturnsÙ¯‚Ù°ƒcsolgndarrayÙ¹‚ƒÙ§x#An array (of similar array type as Ù£ƒbx0ööÙ§x ) containing the final solution.€ögSummaryÙ¯‚Ù¹‚Ù§xFFind a root of a function, in a way suitable for large-scale problems.€öhWarningsÙ¯‚€öeWarnsÙ¯‚€öfYieldsÙ¯‚€ö‡gSummaryjParametersgReturnsfRaiseshSee AlsoeNotesjReferencesx/scipy/optimize/_nonlin.pysr<class 'function'>x9scipy.signal._filter_design.optimize._nonlin.nonlin_solveÙ¯‚€ö‚Ù¼ƒÙ»ƒhJacobianxscipy.optimize._nonlin.Jacobianõ€öÙ¼ƒÙ»ƒjasjacobianx!scipy.optimize._nonlin.asjacobianõ€öe1.8.0Ù«xİnonlin_solve(F, x0, jacobian='krylov', iter=None, verbose=False, maxiter=None, f_tol=None, f_rtol=None, x_tol=None, x_rtol=None, tol_norm=None, line_search='armijo', callback=None, full_output=False, raise_exception=True)öx#scipy.optimize._nonlin.nonlin_solve€