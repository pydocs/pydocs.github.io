Ùª­jAttributesÙ¯‚€öpExtended SummaryÙ¯‚€ögMethodsÙ¯‚€öeNotesÙ¯‚ƒÙ¹‚Ù§xIThis conjugate gradient algorithm is based on that of Polak and Ribiere .€Ù¹‚Ù§x4Conjugate gradient methods tend to work better when:€ÙÇ…Ù¹‚‚Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ§xY has a unique global minimizing point, and no local minima or    other stationary points,€Ù¹‚‚Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ§x` is, at least locally, reasonably well approximated by a    quadratic function of the variables,€Ù¹‚‚Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ§x- is continuous and has a continuous gradient,€Ù¹‚‚Ù¢„ffprimeÙ „escipye1.8.0fmodulex-scipy.optimize._root_scalar.MemoizeDer.fprimefmoduleõÙ§x3 is not too large, e.g., has a norm less than 1000,€Ù¹‚‡Ù§sThe initial guess, Ù¢„bx0Ù „ööelocalbx0elocalõÙ§x, is reasonably close to Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ§x  's global    minimizing point, Ù¢„dxoptÙ „ööelocaldxoptelocalõÙ§a.€öpOther ParametersÙ¯‚€öjParametersÙ¯‚ŒÙ°ƒafxcallable, ``f(x, *args)``Ù¹‚‡Ù§x)Objective function to be minimized. Here Ù£ƒaxööÙ§x^ must be a 1-D array of the variables that are to be changed in the search for a minimum, and Ù¢„dargsÙ „ööelocaldargselocalõÙ§x% are the other (fixed) parameters of Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ§a.€Ù°ƒbx0gndarrayÙ¹‚…Ù§x$A user-supplied initial estimate of Ù¢„dxoptÙ „ööelocaldxoptelocalõÙ§w, the optimal value of Ù£ƒaxööÙ§x#. It must be a 1-D array of values.€Ù°ƒffprimex(callable, ``fprime(x, *args)``, optionalÙ¹‚Ù§x(A function that returns the gradient of Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ§d at Ù£ƒaxööÙ§g. Here Ù£ƒaxööÙ§e and Ù¢„dargsÙ „ööelocaldargselocalõÙ§x are as described above for Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ§xx. The returned value must be a 1-D array. Defaults to None, in which case the gradient is approximated numerically (see Ù¢„gepsilonÙ „ööelocalgepsilonelocalõÙ§i, below).€Ù°ƒdargsotuple, optionalÙ¹‚‰Ù§xParameter values passed to Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ§e and Ù¢„ffprimeÙ „escipye1.8.0fmodulex-scipy.optimize._root_scalar.MemoizeDer.fprimefmoduleõÙ§xg. Must be supplied whenever additional fixed parameters are needed to completely specify the functions Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ§e and Ù¢„ffprimeÙ „escipye1.8.0fmodulex-scipy.optimize._root_scalar.MemoizeDer.fprimefmoduleõÙ§a.€Ù°ƒdgtolofloat, optionalÙ¹‚ƒÙ§x0Stop when the norm of the gradient is less than Ù¢„dgtolÙ „ööelocaldgtolelocalõÙ§a.€Ù°ƒdnormofloat, optionalÙ¹‚…Ù§x+Order to use for the norm of the gradient (Ù¡g-np.InfÙ§i is min, Ù¡fnp.InfÙ§i is max).€Ù°ƒgepsilonxfloat or ndarray, optionalÙ¹‚‡Ù§xStep size(s) to use when Ù¢„ffprimeÙ „escipye1.8.0fmodulex-scipy.optimize._root_scalar.MemoizeDer.fprimefmoduleõÙ§xJ is approximated numerically. Can be a scalar or a 1-D array. Defaults to Ù¡isqrt(eps)Ù§x:, with eps the floating point machine precision.  Usually Ù¡isqrt(eps)Ù§q is about 1.5e-8.€Ù°ƒgmaxitermint, optionalÙ¹‚ƒÙ§x4Maximum number of iterations to perform. Default is Ù¡m200 * len(x0)Ù§a.€Ù°ƒkfull_outputnbool, optionalÙ¹‚‹Ù§pIf True, return Ù¢„dfoptÙ „ööelocaldfoptelocalõÙ§b, Ù¢„jfunc_callsÙ „ööelocaljfunc_callselocalõÙ§b, Ù¢„jgrad_callsÙ „ööelocaljgrad_callselocalõÙ§f, and Ù¢„hwarnflagÙ „ööelocalhwarnflagelocalõÙ§p in addition to Ù¢„dxoptÙ „ööelocaldxoptelocalõÙ§xV.  See the Returns section below for additional information on optional return values.€Ù°ƒddispnbool, optionalÙ¹‚ƒÙ§x3If True, return a convergence message, followed by Ù¢„dxoptÙ „ööelocaldxoptelocalõÙ§a.€Ù°ƒfretallnbool, optionalÙ¹‚Ù§xBIf True, add to the returned values the results of each iteration.€Ù°ƒhcallbackrcallable, optionalÙ¹‚‡Ù§xKAn optional user-supplied function, called after each iteration. Called as Ù¡lcallback(xk)Ù§h, where Ù¡bxkÙ§x is the current value of Ù¢„bx0Ù „ööelocalbx0elocalõÙ§a.€öfRaisesÙ¯‚€öhReceivesÙ¯‚€ögReturnsÙ¯‚†Ù°ƒdxoptgndarrayÙ¹‚ƒÙ§x#Parameters which minimize f, i.e., Ù¡of(xopt) == foptÙ§a.€Ù°ƒdfoptofloat, optionalÙ¹‚ƒÙ§x/Minimum value found, f(xopt). Only returned if Ù¢„kfull_outputÙ „ööelocalkfull_outputelocalõÙ§i is True.€Ù°ƒjfunc_callsmint, optionalÙ¹‚ƒÙ§x4The number of function_calls made. Only returned if Ù¢„kfull_outputÙ „ööelocalkfull_outputelocalõÙ§i is True.€Ù°ƒjgrad_callsmint, optionalÙ¹‚ƒÙ§x4The number of gradient calls made. Only returned if Ù¢„kfull_outputÙ „ööelocalkfull_outputelocalõÙ§i is True.€Ù°ƒhwarnflagmint, optionalÙ¹‚ƒÙ§x4Integer value with warning status, only returned if Ù¢„kfull_outputÙ „ööelocalkfull_outputelocalõÙ§i is True.€Ù°ƒgallvecsxlist of ndarray, optionalÙ¹‚ƒÙ§xKList of arrays, containing the results at each iteration. Only returned if Ù¢„fretallÙ „ööelocalfretallelocalõÙ§i is True.€ögSummaryÙ¯‚Ù¹‚Ù§xCMinimize a function using a nonlinear conjugate gradient algorithm.€öhWarningsÙ¯‚€öeWarnsÙ¯‚€öfYieldsÙ¯‚€ö‡gSummaryjParametersgReturnshSee AlsoeNotesjReferenceshExamplesx/scipy/optimize/_optimize.pysr<class 'function'>x,scipy.signal._filter_design.optimize.fmin_cgÙ¯‚†Ù¹‚…Ù§x4Example 1: seek the minimum value of the expression Ù¡x'a*u**2 + b*u*v + c*v**2 + d*u + e*v + fÙ§x9 for given values of the parameters and an initial guess Ù¡o(u, v) = (0, 0)Ù§a.€Ù´ƒ™
Ù±‚`dargsÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`a(Ù±‚bmia2Ù±‚`a,Ù±‚`a Ù±‚bmia3Ù±‚`a,Ù±‚`a Ù±‚bmia7Ù±‚`a,Ù±‚`a Ù±‚bmia8Ù±‚`a,Ù±‚`a Ù±‚bmia9Ù±‚`a,Ù±‚`a Ù±‚bmib10Ù±‚`a)Ù±‚`b  Ù±‚bc1r# parameter valuesÙ±‚`a
Ù±‚akcdefÙ±‚`a Ù±‚bnfÙ¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ±‚`a(Ù±‚`axÙ±‚`a,Ù±‚`a Ù±‚aoa*Ù±‚`dargsÙ±‚`a)Ù±‚`a:Ù±‚`a
Ù±‚`d    Ù±‚`auÙ±‚`a,Ù±‚`a Ù±‚`avÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`axÙ±‚`a
Ù±‚`d    Ù±‚`aaÙ±‚`a,Ù±‚`a Ù±‚`abÙ±‚`a,Ù±‚`a Ù±‚`acÙ±‚`a,Ù±‚`a Ù±‚`Ù¢„adÙ „escipye1.8.0fmodulex9scipy.sparse.linalg._expm_multiply.LazyOperatorNormInfo.dfmoduleõÙ±‚`a,Ù±‚`a Ù±‚`aeÙ±‚`a,Ù±‚`a Ù±‚`Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`dargsÙ±‚`a
Ù±‚`d    Ù±‚akÙ¢„freturnÙ „escipye1.8.0fmodulex(scipy.integrate._ode.ode.get_return_codefmoduleõÙ±‚`a Ù±‚`aaÙ±‚aoa*Ù±‚`auÙ±‚aoa*Ù±‚aoa*Ù±‚bmia2Ù±‚`a Ù±‚aoa+Ù±‚`a Ù±‚`abÙ±‚aoa*Ù±‚`auÙ±‚aoa*Ù±‚`avÙ±‚`a Ù±‚aoa+Ù±‚`a Ù±‚`acÙ±‚aoa*Ù±‚`avÙ±‚aoa*Ù±‚aoa*Ù±‚bmia2Ù±‚`a Ù±‚aoa+Ù±‚`a Ù±‚`Ù¢„adÙ „escipye1.8.0fmodulex9scipy.sparse.linalg._expm_multiply.LazyOperatorNormInfo.dfmoduleõÙ±‚aoa*Ù±‚`auÙ±‚`a Ù±‚aoa+Ù±‚`a Ù±‚`aeÙ±‚aoa*Ù±‚`avÙ±‚`a Ù±‚aoa+Ù±‚`a Ù±‚`Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ±‚`a
Ù±‚akcdefÙ±‚`a Ù±‚bnfegradfÙ±‚`a(Ù±‚`axÙ±‚`a,Ù±‚`a Ù±‚aoa*Ù±‚`dargsÙ±‚`a)Ù±‚`a:Ù±‚`a
Ù±‚`d    Ù±‚`auÙ±‚`a,Ù±‚`a Ù±‚`avÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`axÙ±‚`a
Ù±‚`d    Ù±‚`aaÙ±‚`a,Ù±‚`a Ù±‚`abÙ±‚`a,Ù±‚`a Ù±‚`acÙ±‚`a,Ù±‚`a Ù±‚`Ù¢„adÙ „escipye1.8.0fmodulex9scipy.sparse.linalg._expm_multiply.LazyOperatorNormInfo.dfmoduleõÙ±‚`a,Ù±‚`a Ù±‚`aeÙ±‚`a,Ù±‚`a Ù±‚`Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`dargsÙ±‚`a
Ù±‚`d    Ù±‚`bguÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚bmia2Ù±‚aoa*Ù±‚`aaÙ±‚aoa*Ù±‚`auÙ±‚`a Ù±‚aoa+Ù±‚`a Ù±‚`abÙ±‚aoa*Ù±‚`avÙ±‚`a Ù±‚aoa+Ù±‚`a Ù±‚`Ù¢„adÙ „escipye1.8.0fmodulex9scipy.sparse.linalg._expm_multiply.LazyOperatorNormInfo.dfmoduleõÙ±‚`e     Ù±‚bc1x# u-component of the gradientÙ±‚`a
Ù±‚`d    Ù±‚`bgvÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`abÙ±‚aoa*Ù±‚`auÙ±‚`a Ù±‚aoa+Ù±‚`a Ù±‚bmia2Ù±‚aoa*Ù±‚`acÙ±‚aoa*Ù±‚`avÙ±‚`a Ù±‚aoa+Ù±‚`a Ù±‚`aeÙ±‚`e     Ù±‚bc1x# v-component of the gradientÙ±‚`a
Ù±‚`d    Ù±‚akÙ¢„freturnÙ „escipye1.8.0fmodulex(scipy.integrate._ode.ode.get_return_codefmoduleõÙ±‚`a Ù±‚`Ù¢„bnpÙ „enumpyf1.22.3fmoduleenumpyfmoduleõÙ±‚aoa.Ù±‚`Ù¢„gasarrayÙ „enumpyf1.22.3fmodulemnumpy.asarrayfmoduleõÙ±‚`a(Ù±‚`a(Ù±‚`bguÙ±‚`a,Ù±‚`a Ù±‚`bgvÙ±‚`a)Ù±‚`a)Ù±‚`a
Ù±‚`Ù¢„bx0Ù „enumpyf1.22.3fmodulemnumpy.ndarrayfmoduleõÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„bnpÙ „enumpyf1.22.3fmoduleenumpyfmoduleõÙ±‚aoa.Ù±‚`Ù¢„gasarrayÙ „enumpyf1.22.3fmodulemnumpy.asarrayfmoduleõÙ±‚`a(Ù±‚`a(Ù±‚bmia0Ù±‚`a,Ù±‚`a Ù±‚bmia0Ù±‚`a)Ù±‚`a)Ù±‚`b  Ù±‚bc1p# Initial guess.Ù±‚`a
Ù±‚bkndfromÙ±‚`a Ù±‚bnnÙ¢„escipyÙ „escipye1.8.0fmoduleescipyfmoduleõÙ±‚`a Ù±‚bknfimportÙ±‚`a Ù±‚`Ù¢„hoptimizeÙ „escipye1.8.0fmodulenscipy.optimizefmoduleõÙ±‚`a
Ù±‚`dres1Ù±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„hoptimizeÙ „escipye1.8.0fmodulenscipy.optimizefmoduleõÙ±‚aoa.Ù±‚`Ù¢„gfmin_cgÙ „escipye1.8.0fmodulex scipy.optimize._optimize.fmin_cgfmoduleõÙ±‚`a(Ù±‚`Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ±‚`a,Ù±‚`a Ù±‚`Ù¢„bx0Ù „enumpyf1.22.3fmodulemnumpy.ndarrayfmoduleõÙ±‚`a,Ù±‚`a Ù±‚`Ù¢„ffprimeÙ „escipye1.8.0fmodulex-scipy.optimize._root_scalar.MemoizeDer.fprimefmoduleõÙ±‚aoa=Ù±‚`egradfÙ±‚`a,Ù±‚`a Ù±‚`dargsÙ±‚aoa=Ù±‚`dargsÙ±‚`a)x¨Optimization terminated successfully.
         Current function value: 1.617021
         Iterations: 4
         Function evaluations: 8
         Gradient evaluations: 8fexecedÙ´ƒÙ±‚`dres1x!array([-1.80851064, -0.25531915])fexecedÙ¹‚…Ù§x,Example 2: solve the same problem using the Ù£ƒhminimizeööÙ§q function. (This Ù£ƒfmyoptsööÙ§x— dictionary shows all of the available options, although in practice only non-default values would be needed. The returned value will be a dictionary.)€Ù´ƒ˜fÙ±‚`doptsÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`a{Ù±‚bs1a'Ù±‚bs1gmaxiterÙ±‚bs1a'Ù±‚`a Ù±‚`a:Ù±‚`a Ù±‚bkcdNoneÙ±‚`a,Ù±‚`d    Ù±‚bc1p# default value.Ù±‚`a
Ù±‚`h        Ù±‚bs1a'Ù±‚bs1ddispÙ±‚bs1a'Ù±‚`a Ù±‚`a:Ù±‚`a Ù±‚bkcdTrueÙ±‚`a,Ù±‚`d    Ù±‚bc1t# non-default value.Ù±‚`a
Ù±‚`h        Ù±‚bs1a'Ù±‚bs1dgtolÙ±‚bs1a'Ù±‚`a Ù±‚`a:Ù±‚`a Ù±‚bmfd1e-5Ù±‚`a,Ù±‚`d    Ù±‚bc1p# default value.Ù±‚`a
Ù±‚`h        Ù±‚bs1a'Ù±‚bs1dnormÙ±‚bs1a'Ù±‚`a Ù±‚`a:Ù±‚`a Ù±‚`Ù¢„bnpÙ „enumpyf1.22.3fmoduleenumpyfmoduleõÙ±‚aoa.Ù±‚`cinfÙ±‚`a,Ù±‚`b  Ù±‚bc1p# default value.Ù±‚`a
Ù±‚`h        Ù±‚bs1a'Ù±‚bs1cepsÙ±‚bs1a'Ù±‚`a Ù±‚`a:Ù±‚`a Ù±‚bmfv1.4901161193847656e-08Ù±‚`a}Ù±‚`b  Ù±‚bc1p# default value.Ù±‚`a
Ù±‚`dres2Ù±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„hoptimizeÙ „escipye1.8.0fmodulenscipy.optimizefmoduleõÙ±‚aoa.Ù±‚`hminimizeÙ±‚`a(Ù±‚`Ù¢„afÙ „escipye1.8.0fmodulex8scipy.optimize._bglu_dense._consider_refactor.<locals>.ffmoduleõÙ±‚`a,Ù±‚`a Ù±‚`Ù¢„bx0Ù „enumpyf1.22.3fmodulemnumpy.ndarrayfmoduleõÙ±‚`a,Ù±‚`a Ù±‚`cjacÙ±‚aoa=Ù±‚`egradfÙ±‚`a,Ù±‚`a Ù±‚`dargsÙ±‚aoa=Ù±‚`dargsÙ±‚`a,Ù±‚`a
Ù±‚`x                         Ù±‚`Ù¢„fmethodÙ „escipye1.8.0fmodulex1scipy.sparse._data._create_method.<locals>.methodfmoduleõÙ±‚aoa=Ù±‚bs1a'Ù±‚bs1bCGÙ±‚bs1a'Ù±‚`a,Ù±‚`a Ù±‚`goptionsÙ±‚aoa=Ù±‚`doptsÙ±‚`a)x¤Optimization terminated successfully.
        Current function value: 1.617021
        Iterations: 4
        Function evaluations: 8
        Gradient evaluations: 8fexecedÙ´ƒ…Ù±‚`dres2Ù±‚aoa.Ù±‚`axÙ±‚`b  Ù±‚bc1o# minimum foundx!array([-1.80851064, -0.25531915])fexecedöÙ¼ƒÙ»ƒhminimizeööÙ¹‚‡Ù§xcommon interface to all Ù¢„nscipy.optimizeÙ „escipye1.8.0fmodulenscipy.optimizefmoduleõÙ§x} algorithms for unconstrained and constrained minimization of multivariate functions. It provides an alternative way to call Ù¡gfmin_cgÙ§p, by specifying Ù¡kmethod='CG'Ù§a.€öe1.8.0Ù«x˜fmin_cg(f, x0, fprime=None, args=(), gtol=1e-05, norm=inf, epsilon=1.4901161193847656e-08, maxiter=None, full_output=0, disp=1, retall=0, callback=None)öx scipy.optimize._optimize.fmin_cg€