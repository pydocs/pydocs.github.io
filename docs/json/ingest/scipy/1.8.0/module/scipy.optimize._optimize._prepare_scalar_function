Ùª­jAttributesÙ¯‚€öpExtended SummaryÙ¯‚€ögMethodsÙ¯‚€öeNotesÙ¯‚€öpOther ParametersÙ¯‚€öjParametersÙ¯‚ˆÙ°ƒcfunhcallableƒÙ¹‚Ù§x'The objective function to be minimized.€Ù·x``fun(x, *args) -> float``Ù¹‚…Ù§fwhere Ù¡axÙ§x% is an 1-D array with shape (n,) and Ù¡dargsÙ§xN is a tuple of the fixed parameters needed to completely specify the function.€Ù°ƒbx0sndarray, shape (n,)Ù¹‚Ù§xeInitial guess. Array of real elements of size (n,), where 'n' is the number of independent variables.€Ù°ƒcjacx7{callable,  '2-point', '3-point', 'cs', None}, optionalƒÙ¹‚Ù§xxMethod for computing the gradient vector. If it is a callable, it should be a function that returns the gradient vector:€Ù·x+``jac(x, *args) -> array_like, shape (n,)``Ù¹‚…Ù§jIf one of Ù£ƒx{'2-point', '3-point', 'cs'}ööÙ§x] is selected then the gradient is calculated with a relative step for finite differences. If Ù¡dNoneÙ§xB, then two-point finite differences with an absolute step is used.€Ù°ƒdargsotuple, optionalÙ¹‚…Ù§xFExtra arguments passed to the objective function and its derivatives (Ù¢„cfunÙ „ööelocalcfunelocalõÙ§b, Ù¢„cjacÙ „ööelocalcjacelocalõÙ§l functions).€Ù°ƒfboundsrsequence, optionalÙ¹‚Ù§x5Bounds on variables. 'new-style' bounds are required.€Ù°ƒcepspfloat or ndarrayÙ¹‚ƒÙ§cIf Ù£ƒkjac is NoneööÙ§xa the absolute step size used for numerical approximation of the jacobian via forward differences.€Ù°ƒtfinite_diff_rel_stepxNone or array_like, optionalÙ¹‚‰Ù§cIf Ù£ƒx#jac in ['2-point', '3-point', 'cs']ööÙ§xr the relative step size to use for numerical approximation of the jacobian. The absolute step size is computed as Ù¡x)h = rel_step * sign(x0) * max(1, abs(x0))Ù§x0, possibly adjusted to fit into the bounds. For Ù¡pmethod='3-point'Ù§m the sign of Ù£ƒahööÙ§xC is ignored. If None (default) then step is selected automatically.€Ù°ƒdhessx-{callable,  '2-point', '3-point', 'cs', None}ƒÙ¹‚Ù§xTComputes the Hessian matrix. If it is callable, it should return the Hessian matrix:€Ù·x?``hess(x, *args) -> {LinearOperator, spmatrix, array}, (n, n)``Ù¹‚Ù§y=Alternatively, the keywords {'2-point', '3-point', 'cs'} select a finite difference scheme for numerical estimation. Whenever the gradient is estimated via finite-differences, the Hessian cannot be estimated with options {'2-point', '3-point', 'cs'} and needs to be estimated using one of the quasi-Newton strategies.€öfRaisesÙ¯‚€öhReceivesÙ¯‚€ögReturnsÙ¯‚Ù°ƒbsfnScalarFunction€ögSummaryÙ¯‚Ù¹‚Ù§x^Creates a ScalarFunction object for use with scalar minimizers (BFGS/LBFGSB/SLSQP/TNC/CG/etc).€öhWarningsÙ¯‚€öeWarnsÙ¯‚€öfYieldsÙ¯‚€öƒgSummaryjParametersgReturnsx/scipy/optimize/_optimize.py¯r<class 'function'>xHscipy.signal._filter_design.optimize._lbfgsb_py._prepare_scalar_functionÙ¯‚€ö€e1.8.0Ù«xu_prepare_scalar_function(fun, x0, jac=None, args=(), bounds=None, epsilon=None, finite_diff_rel_step=None, hess=None)öx1scipy.optimize._optimize._prepare_scalar_function€