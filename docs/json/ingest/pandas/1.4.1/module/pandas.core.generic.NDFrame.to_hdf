Ùª­jAttributesÙ¯‚€öpExtended SummaryÙ¯‚„Ù¹‚Ù§yHierarchical Data Format (HDF) is self-describing, allowing an application to interpret the structure and contents of a file with no outside information. One HDF file can hold a mix of related objects which can be accessed as a group or as individual objects.€Ù¹‚Ù§xqIn order to add another DataFrame or Series to an existing HDF file please use append mode and a different a key.€ÙÆƒgwarning`Ù¹‚Ù§xtOne can store a subclass of ``DataFrame`` or ``Series`` to HDF5, but the type of the subclass is lost upon storing. €Ù¹‚ƒÙ§xFor more information see the Ù£ƒtuser guide <io.hdf5>öcrefÙ§a.€ögMethodsÙ¯‚€öeNotesÙ¯‚€öpOther ParametersÙ¯‚€öjParametersÙ¯‚ŒÙ°ƒkpath_or_bufvstr or pandas.HDFStoreÙ¹‚Ù§xFile path or HDFStore object.€Ù°ƒckeycstrÙ¹‚Ù§x&Identifier for the group in the store.€Ù°ƒdmodex{'a', 'w', 'r+'}, default 'a'‚Ù¹‚Ù§rMode to open file:€ÙÈƒÙ¹‚Ù§x['w': write, a new file is created (an existing file with   the same name would be deleted).€Ù¹‚Ù§xp'a': append, an existing file is opened for reading and   writing, and if the file does not exist it is created.€Ù¹‚Ù§x6'r+': similar to 'a', but the file must already exist.€Ù°ƒicomplevels{0-9}, default NoneÙ¹‚Ù§xRSpecifies a compression level for data. A value of 0 or None disables compression.€Ù°ƒgcomplibx1{'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'Ù¹‚Ù§yNSpecifies the compression library to be used. As of v0.20.2 these additional compressors for Blosc are supported (default if no compressor specified: 'bloscblosclz'): {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy', 'blosc:zlib', 'blosc:zstd'}. Specifying a compression library which is not available issues a ValueError.€Ù°ƒfappendsbool, default FalseÙ¹‚Ù§x9For Table formats, append the input data to the existing.€Ù°ƒfformatx){'fixed', 'table', None}, default 'fixed'‚Ù¹‚Ù§pPossible values:€ÙÈƒÙ¹‚Ù§xN'fixed': Fixed format. Fast writing/reading. Not-appendable,   nor searchable.€Ù¹‚Ù§x©'table': Table format. Write as a PyTables Table structure   which may perform worse but allow more flexible operations   like searching / selecting subsets of the data.€Ù¹‚Ù§x^If None, pd.get_option('io.hdf.default_format') is checked,   followed by fallback to "fixed".€Ù°ƒferrorsustr, default 'strict'Ù¹‚ƒÙ§xZSpecifies how encoding and decoding errors are to be handled. See the errors argument for Ù¢„dopenÙ „fpandase1.4.1fmodulex pandas.io.pytables.HDFStore.openfmoduleõÙ§x for a full list of options.€Ù°ƒhencodingtstr, default "UTF-8"€Ù°ƒlmin_itemsizeudict or int, optionalÙ¹‚Ù§x5Map column names to minimum string sizes for columns.€Ù°ƒgnan_repmAny, optionalÙ¹‚Ù§xBHow to represent null values as str. Not allowed with append=True.€Ù°ƒldata_columnsx!list of columns or True, optionalÙ¹‚ƒÙ§x›List of columns to create as indexed data columns for on-disk queries, or True to use all columns. By default only the axes of the object are indexed. See Ù£ƒxio.hdf5-query-data-columnsöcrefÙ§x$. Applicable only to format='table'.€öfRaisesÙ¯‚€öhReceivesÙ¯‚€ögReturnsÙ¯‚€ögSummaryÙ¯‚Ù¹‚Ù§x8Write the contained data to an HDF5 file using HDFStore.€öhWarningsÙ¯‚€öeWarnsÙ¯‚€öfYieldsÙ¯‚€ö…gSummarypExtended SummaryjParametershSee AlsohExamplesw/pandas/core/generic.py
Yr<class 'function'>x pandas.core.frame.NDFrame.to_hdfÙ¯‚†Ù´ƒ˜XÙ±‚`bdfÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`bpdÙ±‚aoa.Ù±‚`Ù¢„iDataFrameÙ „fpandase1.4.1fmodulexpandas.core.frame.DataFramefmoduleõÙ±‚`a(Ù±‚`a{Ù±‚bs1a'Ù±‚bs1aAÙ±‚bs1a'Ù±‚`a:Ù±‚`a Ù±‚`a[Ù±‚bmia1Ù±‚`a,Ù±‚`a Ù±‚bmia2Ù±‚`a,Ù±‚`a Ù±‚bmia3Ù±‚`a]Ù±‚`a,Ù±‚`a Ù±‚bs1a'Ù±‚bs1aBÙ±‚bs1a'Ù±‚`a:Ù±‚`a Ù±‚`a[Ù±‚bmia4Ù±‚`a,Ù±‚`a Ù±‚bmia5Ù±‚`a,Ù±‚`a Ù±‚bmia6Ù±‚`a]Ù±‚`a}Ù±‚`a,Ù±‚`a
Ù±‚`r                  Ù±‚`eindexÙ±‚aoa=Ù±‚`a[Ù±‚bs1a'Ù±‚bs1aaÙ±‚bs1a'Ù±‚`a,Ù±‚`a Ù±‚bs1a'Ù±‚bs1abÙ±‚bs1a'Ù±‚`a,Ù±‚`a Ù±‚bs1a'Ù±‚bs1acÙ±‚bs1a'Ù±‚`a]Ù±‚`a)Ù±‚`b  Ù±‚bc1p# doctest: +SKIPÙ±‚`a
Ù±‚`bdfÙ±‚aoa.Ù±‚`Ù¢„fto_hdfÙ „fpandase1.4.1fmodulex"pandas.core.generic.NDFrame.to_hdffmoduleõÙ±‚`a(Ù±‚bs1a'Ù±‚bs1gdata.h5Ù±‚bs1a'Ù±‚`a,Ù±‚`a Ù±‚`ckeyÙ±‚aoa=Ù±‚bs1a'Ù±‚bs1bdfÙ±‚bs1a'Ù±‚`a,Ù±‚`a Ù±‚`dmodeÙ±‚aoa=Ù±‚bs1a'Ù±‚bs1awÙ±‚bs1a'Ù±‚`a)Ù±‚`b  Ù±‚bc1p# doctest: +SKIP`hcompiledÙ¹‚Ù§x+We can add another object to the same file:€Ù´ƒ˜)Ù±‚`asÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`bpdÙ±‚aoa.Ù±‚`Ù¢„fSeriesÙ „fpandase1.4.1fmodulexpandas.core.series.SeriesfmoduleõÙ±‚`a(Ù±‚`a[Ù±‚bmia1Ù±‚`a,Ù±‚`a Ù±‚bmia2Ù±‚`a,Ù±‚`a Ù±‚bmia3Ù±‚`a,Ù±‚`a Ù±‚bmia4Ù±‚`a]Ù±‚`a)Ù±‚`b  Ù±‚bc1p# doctest: +SKIPÙ±‚`a
Ù±‚`asÙ±‚aoa.Ù±‚`Ù¢„fto_hdfÙ „fpandase1.4.1fmodulex"pandas.core.generic.NDFrame.to_hdffmoduleõÙ±‚`a(Ù±‚bs1a'Ù±‚bs1gdata.h5Ù±‚bs1a'Ù±‚`a,Ù±‚`a Ù±‚`ckeyÙ±‚aoa=Ù±‚bs1a'Ù±‚bs1asÙ±‚bs1a'Ù±‚`a)Ù±‚`b  Ù±‚bc1p# doctest: +SKIP`hcompiledÙ¹‚Ù§vReading from HDF file:€Ù´ƒÙ±‚`bpdÙ±‚aoa.Ù±‚`Ù¢„hread_hdfÙ „fpandase1.4.1fmodulexpandas.io.pytables.read_hdffmoduleõÙ±‚`a(Ù±‚bs1a'Ù±‚bs1gdata.h5Ù±‚bs1a'Ù±‚`a,Ù±‚`a Ù±‚bs1a'Ù±‚bs1bdfÙ±‚bs1a'Ù±‚`a)Ù±‚`b  Ù±‚bc1p# doctest: +SKIPxA  B
a  1  4
b  2  5
c  3  6hcompiledÙ´ƒÙ±‚`bpdÙ±‚aoa.Ù±‚`Ù¢„hread_hdfÙ „fpandase1.4.1fmodulexpandas.io.pytables.read_hdffmoduleõÙ±‚`a(Ù±‚bs1a'Ù±‚bs1gdata.h5Ù±‚bs1a'Ù±‚`a,Ù±‚`a Ù±‚bs1a'Ù±‚bs1asÙ±‚bs1a'Ù±‚`a)Ù±‚`b  Ù±‚bc1p# doctest: +SKIPx(0    1
1    2
2    3
3    4
dtype: int64hcompiledö…Ù¼ƒÙ»ƒpDataFrame.to_csvööÙ¹‚Ù§xWrite out to a csv file.€öÙ¼ƒÙ»ƒtDataFrame.to_featherx&pandas.core.frame.DataFrame.to_featherõÙ¹‚Ù§x(Write out feather-format for DataFrames.€öÙ¼ƒÙ»ƒtDataFrame.to_parquetx&pandas.core.frame.DataFrame.to_parquetõÙ¹‚Ù§x/Write a DataFrame to the binary parquet format.€öÙ¼ƒÙ»ƒpDataFrame.to_sqlööÙ¹‚Ù§uWrite to a SQL table.€öÙ¼ƒÙ»ƒhread_hdfxpandas.io.pytables.read_hdfõÙ¹‚Ù§sRead from HDF file.€öe1.4.1Ù«yŸto_hdf(self, path_or_buf, key: 'str', mode: 'str' = 'a', complevel: 'int | None' = None, complib: 'str | None' = None, append: 'bool_t' = False, format: 'str | None' = None, index: 'bool_t' = True, min_itemsize: 'int | dict[str, int] | None' = None, nan_rep=None, dropna: 'bool_t | None' = None, data_columns: 'Literal[True] | list[str] | None' = None, errors: 'str' = 'strict', encoding: 'str' = 'UTF-8') -> 'None'öx"pandas.core.generic.NDFrame.to_hdf€