Ùª­jAttributesÙ¯‚€öpExtended SummaryÙ¯‚ƒÙ¹‚Ù§yThis method should pack its current state and is called by the Client when communicating with the Scheduler. The Scheduler will then use .__dask_distributed_unpack__(data, ...) to unpack the state, materialize the layer, and merge it into the global task graph.€Ù¹‚Ù§yeThe returned state must be compatible with Distributed's scheduler, which means it must obey the following:   - Serializable by msgpack (notice, msgpack converts lists to tuples)   - All remote data must be unpacked (see unpack_remotedata())   - All keys must be converted to strings now or when unpacking   - All tasks must be serialized (see dumps_task())€Ù¹‚Ù§xºThe default implementation materialize the layer thus layers such as Blockwise and ShuffleLayer should implement a specialized pack and unpack function in order to avoid materialization.€ögMethodsÙ¯‚€öeNotesÙ¯‚€öpOther ParametersÙ¯‚€öjParametersÙ¯‚„Ù°ƒx all_hlg_keys: Iterable[Hashable]`Ù¹‚Ù§x All keys in the high level graph€Ù°ƒx.known_key_dependencies: Mapping[Hashable, set]`Ù¹‚Ù§xAlready known dependencies€Ù°ƒxclient: distributed.Client`Ù¹‚Ù§x!The client calling this function.€Ù°ƒkclient_keysrIterable[Hashable]Ù¹‚Ù§x%List of keys requested by the client.€öfRaisesÙ¯‚€öhReceivesÙ¯‚€ögReturnsÙ¯‚Ù°ƒ`x%state: Object serializable by msgpackÙ¹‚Ù§x'Scheduler compatible state of the layer€ögSummaryÙ¯‚Ù¹‚Ù§x9Pack the layer for scheduler communication in Distributed€öhWarningsÙ¯‚€öeWarnsÙ¯‚€öfYieldsÙ¯‚€ö„gSummarypExtended SummaryjParametersgReturnsw/dask/highlevelgraph.pyFr<class 'function'>x.dask.blockwise.Layer.__dask_distributed_pack__Ù¯‚€ö€i2021.10.0Ù«x¡__dask_distributed_pack__(self, all_hlg_keys: Iterable[Hashable], known_key_dependencies: Mapping[Hashable, set], client, client_keys: Iterable[Hashable]) -> Anyöx3dask.highlevelgraph.Layer.__dask_distributed_pack__€