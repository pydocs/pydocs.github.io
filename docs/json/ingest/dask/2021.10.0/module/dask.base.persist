Ùª­jAttributesÙ¯‚€öpExtended SummaryÙ¯‚„Ù¹‚Ù§x¡This turns lazy Dask collections into Dask collections with the same metadata, but now with their results fully computed or actively computing in the background.€Ù¹‚ƒÙ§xÕFor example a lazy dask.array built up from many lazy calls will now be a dask.array of the same shape, dtype, chunks, etc., but now with all of those previously lazy tasks either computed in memory as many small Ù¢„knumpy.arrayÙ „enumpya*capiknumpy.arrayfmoduleõÙ§xq (in the single-machine case) or asynchronously running in the background on a cluster (in the distributed case).€Ù¹‚ƒÙ§x(This function operates differently if a Ù¡wdask.distributed.ClientÙ§yo exists and is connected to a distributed scheduler.  In this case this function will return as soon as the task graph has been submitted to the cluster, but before the computations have completed.  Computations will continue asynchronously in the background.  When using this function with the single machine scheduler it blocks until the computations have finished.€Ù¹‚Ù§xcWhen using Dask on a single machine you should ensure that the dataset fits entirely within memory.€ögMethodsÙ¯‚€öeNotesÙ¯‚€öpOther ParametersÙ¯‚€öjParametersÙ¯‚…Ù°ƒw*args: Dask collections`€Ù°ƒischedulerpstring, optionalÙ¹‚Ù§x·Which scheduler to use like "threads", "synchronous" or "processes". If not provided, the default is to check the global settings first, and then fall back to the collection defaults.€Ù°ƒhtraversenbool, optionalÙ¹‚…Ù§xXBy default dask traverses builtin python collections looking for dask objects passed to Ù¡gpersistÙ§xf. For large collections this can be expensive. If none of the arguments contain any dask objects, set Ù¡ntraverse=FalseÙ§x to avoid doing this traversal.€Ù°ƒnoptimize_graphnbool, optionalÙ¹‚Ù§xIf True [default], the graph is optimized before computation. Otherwise the graph is run as is. This can be useful for debugging.€Ù°ƒh**kwargs`Ù¹‚Ù§x4Extra keywords to forward to the scheduler function.€öfRaisesÙ¯‚€öhReceivesÙ¯‚€ögReturnsÙ¯‚Ù°ƒ`x-New dask collections backed by in-memory data€ögSummaryÙ¯‚Ù¹‚Ù§x-Persist multiple Dask collections into memory€öhWarningsÙ¯‚€öeWarnsÙ¯‚€öfYieldsÙ¯‚€ö…gSummarypExtended SummaryhExamplesjParametersgReturnsm/dask/base.pyªr<class 'function'>ldask.persistÙ¯‚„Ù´ƒ˜@Ù±‚`bdfÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`bddÙ±‚aoa.Ù±‚`hread_csvÙ±‚`a(Ù±‚bs1a'Ù±‚bs1n/path/to/*.csvÙ±‚bs1a'Ù±‚`a)Ù±‚`b  Ù±‚bc1p# doctest: +SKIPÙ±‚`a
Ù±‚`bdfÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`bdfÙ±‚`a[Ù±‚`bdfÙ±‚aoa.Ù±‚`dnameÙ±‚`a Ù±‚aob==Ù±‚`a Ù±‚bs1a'Ù±‚bs1eAliceÙ±‚bs1a'Ù±‚`a]Ù±‚`b  Ù±‚bc1p# doctest: +SKIPÙ±‚`a
Ù±‚`bdfÙ±‚`a[Ù±‚bs1a'Ù±‚bs1gin-debtÙ±‚bs1a'Ù±‚`a]Ù±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`bdfÙ±‚aoa.Ù±‚`gbalanceÙ±‚`a Ù±‚aoa<Ù±‚`a Ù±‚bmiÙ¢„a0Ù „ddaski2021.10.0fmodulevdask.array.ufunc.log10fmoduleõÙ±‚`b  Ù±‚bc1p# doctest: +SKIPÙ±‚`a
Ù±‚`bdfÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`bdfÙ±‚aoa.Ù±‚`Ù¢„gpersistÙ „ddaski2021.10.0fmoduleqdask.base.persistfmoduleõÙ±‚`a(Ù±‚`a)Ù±‚`b  Ù±‚bc1x(# triggers computation  # doctest: +SKIP`hcompiledÙ´ƒ‹Ù±‚`bdfÙ±‚aoa.Ù±‚`evalueÙ±‚`a(Ù±‚`a)Ù±‚aoa.Ù±‚`cminÙ±‚`a(Ù±‚`a)Ù±‚`b  Ù±‚bc1x4# future computations are now fast  # doctest: +SKIPc-10hcompiledÙ´ƒ‹Ù±‚`bdfÙ±‚aoa.Ù±‚`evalueÙ±‚`a(Ù±‚`a)Ù±‚aoa.Ù±‚`cmaxÙ±‚`a(Ù±‚`a)Ù±‚`b  Ù±‚bc1p# doctest: +SKIPc100hcompiledÙ´ƒ˜Ù±‚bkndfromÙ±‚`a Ù±‚bnnÙ¢„ddaskÙ „ddaski2021.10.0fmoduleddaskfmoduleõÙ±‚`a Ù±‚bknfimportÙ±‚`a Ù±‚`Ù¢„gpersistÙ „ddaski2021.10.0fmoduleqdask.base.persistfmoduleõÙ±‚`b  Ù±‚bc1x.# use persist function on multiple collectionsÙ±‚`a
Ù±‚`aaÙ±‚`a,Ù±‚`a Ù±‚`abÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„gpersistÙ „ddaski2021.10.0fmoduleqdask.base.persistfmoduleõÙ±‚`a(Ù±‚`aaÙ±‚`a,Ù±‚`a Ù±‚`abÙ±‚`a)Ù±‚`b  Ù±‚bc1p# doctest: +SKIP`hcompiledö€i2021.10.0Ù«xpersist(*args, **kwargs)öqdask.base.persist€