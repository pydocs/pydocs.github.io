{
  "_content": {
    "Attributes": {
      "children": [],
      "title": null
    },
    "Extended Summary": {
      "children": [],
      "title": null
    },
    "Methods": {
      "children": [],
      "title": null
    },
    "Notes": {
      "children": [],
      "title": null
    },
    "Other Parameters": {
      "children": [],
      "title": null
    },
    "Parameters": {
      "children": [
        {
          "type": "Param",
          "data": {
            "param": "image",
            "type_": "(N1,...,NN) ndarray",
            "desc": [
              {
                "type": "Paragraph",
                "data": {
                  "inline": [
                    {
                      "type": "Words",
                      "data": {
                        "value": "Input image."
                      }
                    }
                  ],
                  "inner": []
                }
              }
            ]
          }
        },
        {
          "type": "Param",
          "data": {
            "param": "kernel_size: int or N-tuple of int",
            "type_": "",
            "desc": [
              {
                "type": "Paragraph",
                "data": {
                  "inline": [
                    {
                      "type": "Words",
                      "data": {
                        "value": "Defines the shape of contextual regions used in the algorithm."
                      }
                    }
                  ],
                  "inner": []
                }
              }
            ]
          }
        },
        {
          "type": "Param",
          "data": {
            "param": "clip_limit",
            "type_": "float",
            "desc": [
              {
                "type": "Paragraph",
                "data": {
                  "inline": [
                    {
                      "type": "Words",
                      "data": {
                        "value": "Normalized clipping limit (higher values give more contrast)."
                      }
                    }
                  ],
                  "inner": []
                }
              }
            ]
          }
        },
        {
          "type": "Param",
          "data": {
            "param": "nbins",
            "type_": "int",
            "desc": [
              {
                "type": "Paragraph",
                "data": {
                  "inline": [
                    {
                      "type": "Words",
                      "data": {
                        "value": "Number of gray bins for histogram (\"data range\")."
                      }
                    }
                  ],
                  "inner": []
                }
              }
            ]
          }
        }
      ],
      "title": null
    },
    "Raises": {
      "children": [],
      "title": null
    },
    "Receives": {
      "children": [],
      "title": null
    },
    "Returns": {
      "children": [
        {
          "type": "Param",
          "data": {
            "param": "out",
            "type_": "(N1,...,NN) ndarray",
            "desc": [
              {
                "type": "Paragraph",
                "data": {
                  "inline": [
                    {
                      "type": "Words",
                      "data": {
                        "value": "Equalized image."
                      }
                    }
                  ],
                  "inner": []
                }
              }
            ]
          }
        },
        {
          "type": "Param",
          "data": {
            "param": "",
            "type_": "The number of \"effective\" graylevels in the output image is set by `nbins`;",
            "desc": []
          }
        },
        {
          "type": "Param",
          "data": {
            "param": "",
            "type_": "selecting a small value (eg. 128) speeds up processing and still produce",
            "desc": []
          }
        },
        {
          "type": "Param",
          "data": {
            "param": "",
            "type_": "an output image of good quality. The output image will have the same",
            "desc": []
          }
        },
        {
          "type": "Param",
          "data": {
            "param": "",
            "type_": "minimum and maximum value as the input image. A clip limit smaller than 1",
            "desc": []
          }
        },
        {
          "type": "Param",
          "data": {
            "param": "",
            "type_": "results in standard (non-contrast limited) AHE.",
            "desc": []
          }
        }
      ],
      "title": null
    },
    "Summary": {
      "children": [
        {
          "type": "Paragraph",
          "data": {
            "inline": [
              {
                "type": "Words",
                "data": {
                  "value": "Contrast Limited Adaptive Histogram Equalization."
                }
              }
            ],
            "inner": []
          }
        }
      ],
      "title": null
    },
    "Warnings": {
      "children": [],
      "title": null
    },
    "Warns": {
      "children": [],
      "title": null
    },
    "Yields": {
      "children": [],
      "title": null
    }
  },
  "refs": [],
  "ordered_sections": [
    "Summary",
    "Parameters",
    "Returns"
  ],
  "item_file": "/skimage/exposure/_adapthist.py",
  "item_line": 101,
  "item_type": "<class 'function'>",
  "aliases": [
    "skimage.exposure._adapthist._clahe"
  ],
  "example_section_data": {
    "children": [],
    "title": null
  },
  "see_also": [],
  "version": "0.17.2",
  "signature": "_clahe(image, kernel_size, clip_limit, nbins)",
  "references": null,
  "logo": "logo.png",
  "qa": "skimage.exposure._adapthist._clahe",
  "arbitrary": []
}