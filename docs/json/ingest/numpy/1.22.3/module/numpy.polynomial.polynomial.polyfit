Ùª­jAttributesÙ¯‚€öpExtended SummaryÙ¯‚ƒÙ¹‚Ù§x2Return the coefficients of a polynomial of degree Ù¢„cdegÙ „ööelocalcdegelocalõÙ§x2 that is the least squares fit to the data values Ù¢„ayÙ „ööelocalayelocalõÙ§q given at points Ù¢„axÙ „ööelocalaxelocalõÙ§e. If Ù¢„ayÙ „ööelocalayelocalõÙ§x7 is 1-D the returned coefficients will also be 1-D. If Ù¢„ayÙ „ööelocalayelocalõÙ§x7 is 2-D multiple fits are done, one for each column of Ù¢„ayÙ „ööelocalayelocalõÙ§x‚, and the resulting coefficients are stored in the corresponding columns of a 2-D return. The fitted polynomial(s) are in the form€Ù¤x*p ( x) = c_0 + c_1 * x + ... + c_n * x^n, Ù¹‚…Ù§fwhere Ù£ƒanööÙ§d is Ù¢„cdegÙ „ööelocalcdegelocalõÙ§a.€ögMethodsÙ¯‚€öeNotesÙ¯‚‡Ù¹‚ƒÙ§x3The solution is the coefficients of the polynomial Ù£ƒapööÙ§x6 that minimizes the sum of the weighted squared errors€Ù¤x'E = \sum_j w_j^2 * |y_j - p ( x_j)|^2, Ù¹‚ƒÙ§jwhere the Ù¥cw_jÙ§xg are the weights. This problem is solved by setting up the (typically) over-determined matrix equation:€Ù¤tV ( x) * c = w * y, Ù¹‚Ù§fwhere Ù£ƒaVööÙ§x. is the weighted pseudo Vandermonde matrix of Ù¢„axÙ „ööelocalaxelocalõÙ§b, Ù£ƒacööÙ§x( are the coefficients to be solved for, Ù¢„awÙ „ööelocalawelocalõÙ§v are the weights, and Ù¢„ayÙ „ööelocalayelocalõÙ§xb are the observed values.  This equation is then solved using the singular value decomposition of Ù£ƒaVööÙ§a.€Ù¹‚‹Ù§x"If some of the singular values of Ù£ƒaVööÙ§x+ are so small that they are neglected (and Ù¢„dfullÙ „enumpyf1.22.3fmodulejnumpy.fullfmoduleõÙ§d == Ù¡eFalseÙ§e), a Ù¢„kRankWarningÙ „enumpyf1.22.3fmoduleqnumpy.RankWarningfmoduleõÙ§yv will be raised. This means that the coefficient values may be poorly determined. Fitting to a lower order polynomial will usually get rid of the warning (but may not be what you want, of course; if you have independent reason(s) for choosing the degree which isn't working, you may have to: a) reconsider those reasons, and/or b) reconsider the quality of your data).  The Ù¢„ercondÙ „ööelocalercondelocalõÙ§x— parameter can also be set to a value smaller than its default, but the resulting fit may be spurious and have large contributions from roundoff error.€Ù¹‚Ù§yPPolynomial fits using double precision tend to "fail" at about (polynomial) degree 20. Fits using Chebyshev or Legendre series are generally better conditioned, but much can still depend on the distribution of the sample points and the smoothness of the data.  If the quality of the fit is inadequate, splines may be a good alternative.€öpOther ParametersÙ¯‚€öjParametersÙ¯‚†Ù°ƒaxxarray_like, shape (`M`,)Ù¹‚…Ù§ux-coordinates of the Ù£ƒaMööÙ§v sample (data) points Ù¡l(x[i], y[i])Ù§a.€Ù°ƒayx&array_like, shape (`M`,) or (`M`, `K`)Ù¹‚…Ù§xy-coordinates of the sample points.  Several sets of sample points sharing the same x-coordinates can be (independently) fit with one call to Ù¢„gpolyfitÙ „enumpyf1.22.3fmodulemnumpy.polyfitfmoduleõÙ§s by passing in for Ù¢„ayÙ „ööelocalayelocalõÙ§x3 a 2-D array that contains one data set per column.€Ù°ƒcdeguint or 1-D array_likeÙ¹‚…Ù§x)Degree(s) of the fitting polynomials. If Ù¢„cdegÙ „ööelocalcdegelocalõÙ§x7 is a single integer all terms up to and including the Ù¢„cdegÙ „ööelocalcdegelocalõÙ§x•'th term are included in the fit. For NumPy versions >= 1.11.0 a list of integers specifying the degrees of the terms to include may be used instead.€Ù°ƒercondofloat, optionalÙ¹‚‡Ù§xDRelative condition number of the fit.  Singular values smaller than Ù¢„ercondÙ „ööelocalercondelocalõÙ§xQ, relative to the largest singular value, will be ignored.  The default value is Ù¡jlen(x)*epsÙ§h, where Ù£ƒcepsööÙ§xS is the relative precision of the platform's float type, about 2e-16 in most cases.€Ù°ƒdfullnbool, optionalÙ¹‚…Ù§x9Switch determining the nature of the return value.  When Ù¡eFalseÙ§x8 (the default) just the coefficients are returned; when Ù¡dTrueÙ§xz, diagnostic information from the singular value decomposition (used to solve the fit's matrix equation) is also returned.€Ù°ƒawx"array_like, shape (`M`,), optional‚Ù¹‚‹Ù§x!Weights. If not None, the weight Ù¡dw[i]Ù§x# applies to the unsquared residual Ù¡oy[i] - y_hat[i]Ù§d at Ù¡dx[i]Ù§xD. Ideally the weights are chosen so that the errors of the products Ù¡iw[i]*y[i]Ù§xI all have the same variance.  When using inverse-variance weighting, use Ù¡tw[i] = 1/sigma(y[i])Ù§x.  The default value is None.€ÙÆƒlversionaddeddTODOÙ¹‚Ù§f1.5.0 €öfRaisesÙ¯‚Ù°ƒ`kRankWarning‚Ù¹‚ƒÙ§x_Raised if the matrix in the least-squares fit is rank deficient. The warning is only raised if Ù¡mfull == FalseÙ§x%.  The warnings can be turned off by:€ÙÀxG>>> import warnings
>>> warnings.simplefilter('ignore', np.RankWarning)öhReceivesÙ¯‚€ögReturnsÙ¯‚‚Ù°ƒdcoefx/ndarray, shape (`deg` + 1,) or (`deg` + 1, `K`)Ù¹‚‹Ù§x6Polynomial coefficients ordered from low to high.  If Ù¢„ayÙ „ööelocalayelocalõÙ§x% was 2-D, the coefficients in column Ù£ƒakööÙ§d of Ù¢„dcoefÙ „ööelocaldcoefelocalõÙ§x- represent the polynomial fit to the data in Ù¢„ayÙ „ööelocalayelocalõÙ§c's Ù£ƒakööÙ§k-th column.€Ù°ƒx)[residuals, rank, singular_values, rcond]dlistƒÙ¹‚‚Ù§x"These values are only returned if Ù¡lfull == True€ÙÈ„Ù¹‚Ù§x>residuals -- sum of squared residuals of the least squares fit€Ù¹‚Ù§x;rank -- the numerical rank of the scaled Vandermonde matrix€Ù¹‚Ù§xCsingular_values -- singular values of the scaled Vandermonde matrix€Ù¹‚ƒÙ§rrcond -- value of Ù£ƒercondööÙ§a.€Ù¹‚ƒÙ§vFor more details, see Ù¢„rnumpy.linalg.lstsqÙ „enumpyf1.22.3fmodulernumpy.linalg.lstsqfmoduleõÙ§a.€ögSummaryÙ¯‚Ù¹‚Ù§x*Least-squares fit of a polynomial to data.€öhWarningsÙ¯‚€öeWarnsÙ¯‚€öfYieldsÙ¯‚€öˆgSummarypExtended SummaryjParametersgReturnsfRaiseshSee AlsoeNoteshExamplesx/numpy/polynomial/polynomial.py¾r<class 'function'>x#numpy.polynomial.polynomial.polyfitÙ¯‚…Ù´ƒ˜hÙ±‚`bnpÙ±‚aoa.Ù±‚`Ù¢„frandomÙ „enumpyf1.22.3fmodulelnumpy.randomfmoduleõÙ±‚aoa.Ù±‚`dseedÙ±‚`a(Ù±‚bmic123Ù±‚`a)Ù±‚`a
Ù±‚bkndfromÙ±‚`a Ù±‚bnnÙ¢„enumpyÙ „enumpyf1.22.3fmoduleenumpyfmoduleõÙ±‚bnna.Ù±‚bnnÙ¢„jpolynomialÙ „enumpyf1.22.3fmodulepnumpy.polynomialfmoduleõÙ±‚`a Ù±‚bknfimportÙ±‚`a Ù±‚`Ù¢„jpolynomialÙ „enumpyf1.22.3fmodulepnumpy.polynomialfmoduleõÙ±‚`a Ù±‚akbasÙ±‚`a Ù±‚`aPÙ±‚`a
Ù±‚`axÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`bnpÙ±‚aoa.Ù±‚`Ù¢„hlinspaceÙ „enumpyf1.22.3fmodulennumpy.linspacefmoduleõÙ±‚`a(Ù±‚aoa-Ù±‚bmia1Ù±‚`a,Ù±‚bmia1Ù±‚`a,Ù±‚bmib51Ù±‚`a)Ù±‚`a Ù±‚bc1x%# x "data": [-1, -0.96, ..., 0.96, 1]Ù±‚`a
Ù±‚`ayÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`axÙ±‚aoa*Ù±‚aoa*Ù±‚bmia3Ù±‚`a Ù±‚aoa-Ù±‚`a Ù±‚`axÙ±‚`a Ù±‚aoa+Ù±‚`a Ù±‚`bnpÙ±‚aoa.Ù±‚`Ù¢„frandomÙ „enumpyf1.22.3fmodulelnumpy.randomfmoduleõÙ±‚aoa.Ù±‚`erandnÙ±‚`a(Ù±‚bnbclenÙ±‚`a(Ù±‚`axÙ±‚`a)Ù±‚`a)Ù±‚`a Ù±‚bc1x# x^3 - x + N(0,1) "noise"Ù±‚`a
Ù±‚`acÙ±‚`a,Ù±‚`a Ù±‚`Ù¢„estatsÙ „enumpyf1.22.3fmodulexnumpy.lib.arraypad._get_statsfmoduleõÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`aPÙ±‚aoa.Ù±‚`Ù¢„gpolyfitÙ „enumpyf1.22.3fmodulemnumpy.polyfitfmoduleõÙ±‚`a(Ù±‚`axÙ±‚`a,Ù±‚`ayÙ±‚`a,Ù±‚bmia3Ù±‚`a,Ù±‚`Ù¢„dfullÙ „enumpyf1.22.3fmodulejnumpy.fullfmoduleõÙ±‚aoa=Ù±‚bkcdTrueÙ±‚`a)Ù±‚`a
Ù±‚`bnpÙ±‚aoa.Ù±‚`Ù¢„frandomÙ „enumpyf1.22.3fmodulelnumpy.randomfmoduleõÙ±‚aoa.Ù±‚`dseedÙ±‚`a(Ù±‚bmic123Ù±‚`a)Ù±‚`a
Ù±‚`acÙ±‚`a Ù±‚bc1xA# c[0], c[2] should be approx. 0, c[1] approx. -1, c[3] approx. 1xFarray([ 0.01909725, -1.30598256, -0.00577963,  1.02644286]) # may varyfexecedÙ´ƒƒÙ±‚`Ù¢„estatsÙ „enumpyf1.22.3fmodulexnumpy.lib.arraypad._get_statsfmoduleõÙ±‚`a Ù±‚bc1x8# note the large SSR, explaining the rather poor resultsx… [array([ 38.06116253]), 4, array([ 1.38446749,  1.32119158,  0.50443316, # may vary
          0.28853036]), 1.1324274851176597e-014]fexecedÙ¹‚Ù§x"Same thing without the added noise€Ù´ƒ˜&Ù±‚`ayÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`axÙ±‚aoa*Ù±‚aoa*Ù±‚bmia3Ù±‚`a Ù±‚aoa-Ù±‚`a Ù±‚`axÙ±‚`a
Ù±‚`acÙ±‚`a,Ù±‚`a Ù±‚`Ù¢„estatsÙ „enumpyf1.22.3fmodulexnumpy.lib.arraypad._get_statsfmoduleõÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`aPÙ±‚aoa.Ù±‚`Ù¢„gpolyfitÙ „enumpyf1.22.3fmodulemnumpy.polyfitfmoduleõÙ±‚`a(Ù±‚`axÙ±‚`a,Ù±‚`ayÙ±‚`a,Ù±‚bmia3Ù±‚`a,Ù±‚`Ù¢„dfullÙ „enumpyf1.22.3fmodulejnumpy.fullfmoduleõÙ±‚aoa=Ù±‚bkcdTrueÙ±‚`a)Ù±‚`a
Ù±‚`acÙ±‚`a Ù±‚bc1x?# c[0], c[2] should be "very close to 0", c[1] ~= -1, c[3] ~= 1xKarray([-6.36925336e-18, -1.00000000e+00, -4.08053781e-16,  1.00000000e+00])fexecedÙ´ƒƒÙ±‚`Ù¢„estatsÙ „enumpyf1.22.3fmodulexnumpy.lib.arraypad._get_statsfmoduleõÙ±‚`a Ù±‚bc1x# note the minuscule SSRx‰[array([  7.46346754e-31]), 4, array([ 1.38446749,  1.32119158, # may vary
           0.50443316,  0.28853036]), 1.1324274851176597e-014]fexecedö‰Ù¼ƒÙ»ƒrnumpy.linalg.lstsqrnumpy.linalg.lstsqõÙ¹‚Ù§x-Computes a least-squares fit from the matrix.€öÙ¼ƒÙ»ƒx"numpy.polynomial.chebyshev.chebfitx"numpy.polynomial.chebyshev.chebfitõ€öÙ¼ƒÙ»ƒx numpy.polynomial.hermite.hermfitx numpy.polynomial.hermite.hermfitõ€öÙ¼ƒÙ»ƒx#numpy.polynomial.hermite_e.hermefitx#numpy.polynomial.hermite_e.hermefitõ€öÙ¼ƒÙ»ƒx numpy.polynomial.laguerre.lagfitx numpy.polynomial.laguerre.lagfitõ€öÙ¼ƒÙ»ƒx numpy.polynomial.legendre.legfitx numpy.polynomial.legendre.legfitõ€öÙ¼ƒÙ»ƒgpolyvalmnumpy.polyvalõÙ¹‚Ù§wEvaluates a polynomial.€öÙ¼ƒÙ»ƒjpolyvanderx&numpy.polynomial.polynomial.polyvanderõÙ¹‚Ù§xVandermonde matrix for powers.€öÙ¼ƒÙ»ƒx"scipy.interpolate.UnivariateSplineööÙ¹‚Ù§uComputes spline fits.€öf1.22.3Ù«x2polyfit(x, y, deg, rcond=None, full=False, w=None)öx#numpy.polynomial.polynomial.polyfit€