Ùª­jAttributesÙ¯‚€öpExtended SummaryÙ¯‚ƒÙÆƒdnote`Ù¹‚Ù§xôThis forms part of the old polynomial API. Since version 1.4, the new polynomial API defined in `numpy.polynomial` is preferred. A summary of the differences can be found in the : doc : `transition guide < / reference / routines.polynomials>`. €Ù¹‚Ù§qFit a polynomial Ù¡x#p(x) = p[0] * x**deg + ... + p[deg]Ù§k of degree Ù¢„cdegÙ „ööelocalcdegelocalõÙ§k to points Ù£ƒf(x, y)ööÙ§x#. Returns a vector of coefficients Ù¢„apÙ „ööelocalapelocalõÙ§x/ that minimises the squared error in the order Ù¢„cdegÙ „ööelocalcdegelocalõÙ§b, Ù£ƒedeg-1ööÙ§f, ... Ù£ƒa0ööÙ§a.€Ù¹‚ƒÙ§dThe Ù£ƒx;Polynomial.fit <numpy.polynomial.polynomial.Polynomial.fit>ööÙ§x… class method is recommended for new code as it is more stable numerically. See the documentation of the method for more information.€ögMethodsÙ¯‚€öeNotesÙ¯‚ˆÙ¹‚Ù§x:Any masked values in x is propagated in y, and vice-versa.€Ù¹‚Ù§x(The solution minimizes the squared error€Ù¤x&E = \sum_ { j=0}^k |p ( x_j) - y_j|^2 Ù¹‚Ù§xin the equations::      €ÙÀxœx[0]**n * p[0] + ... + x[0] * p[n-1] + p[n] = y[0]
x[1]**n * p[0] + ... + x[1] * p[n-1] + p[n] = y[1]
...
x[k]**n * p[0] + ... + x[k] * p[n-1] + p[n] = y[k]Ù¹‚ƒÙ§x+The coefficient matrix of the coefficients Ù¢„apÙ „ööelocalapelocalõÙ§x is a Vandermonde matrix.€Ù¹‚ŒÙ¢„gpolyfitÙ „enumpyf1.22.3fmodulemnumpy.polyfitfmoduleõÙ§j issues a Ù¢„kRankWarningÙ „enumpyf1.22.3fmoduleqnumpy.RankWarningfmoduleõÙ§xË when the least-squares fit is badly conditioned. This implies that the best fit is not well-defined due to numerical error. The results may be improved by lowering the polynomial degree or by replacing Ù¢„axÙ „ööelocalaxelocalõÙ§d by Ù¢„axÙ „ööelocalaxelocalõÙ§c - Ù¢„axÙ „ööelocalaxelocalõÙ§m.mean(). The Ù¢„ercondÙ „ööelocalercondelocalõÙ§xÄ parameter can also be set to a value smaller than its default, but the resulting fit may be spurious: including contributions from the small singular values can add numerical noise to the result.€Ù¹‚Ù§y6Note that fitting polynomial coefficients is inherently badly conditioned when the degree of the polynomial is large or the interval of sample points is badly centered. The quality of the fit should always be checked in these cases. When polynomial fits are not satisfactory, splines may be a good alternative.€öpOther ParametersÙ¯‚€öjParametersÙ¯‚‡Ù°ƒaxvarray_like, shape (M,)Ù¹‚ƒÙ§x%x-coordinates of the M sample points Ù¡l(x[i], y[i])Ù§a.€Ù°ƒayx array_like, shape (M,) or (M, K)Ù¹‚Ù§xºy-coordinates of the sample points. Several data sets of sample points sharing the same x-coordinates can be fitted at once by passing in a 2D-array that contains one dataset per column.€Ù°ƒcdegcintÙ¹‚Ù§x Degree of the fitting polynomial€Ù°ƒercondofloat, optionalÙ¹‚Ù§xòRelative condition number of the fit. Singular values smaller than this relative to the largest singular value will be ignored. The default value is len(x)*eps, where eps is the relative precision of the float type, about 2e-16 in most cases.€Ù°ƒdfullnbool, optionalÙ¹‚Ù§xÆSwitch determining nature of return value. When it is False (the default) just the coefficients are returned, when True diagnostic information from the singular value decomposition is also returned.€Ù°ƒawx array_like, shape (M,), optionalÙ¹‚‹Ù§x!Weights. If not None, the weight Ù¡dw[i]Ù§x# applies to the unsquared residual Ù¡oy[i] - y_hat[i]Ù§d at Ù¡dx[i]Ù§xD. Ideally the weights are chosen so that the errors of the products Ù¡iw[i]*y[i]Ù§xI all have the same variance.  When using inverse-variance weighting, use Ù¡tw[i] = 1/sigma(y[i])Ù§x.  The default value is None.€Ù°ƒccovubool or str, optionalÙ¹‚…Ù§qIf given and not Ù¡eFalseÙ§y1, return not just the estimate but also its covariance matrix. By default, the covariance are scaled by chi2/dof, where dof = M - (deg + 1), i.e., the weights are presumed to be unreliable except in a relative sense and everything is scaled such that the reduced chi2 is unity. This scaling is omitted if Ù¡ncov='unscaled'Ù§x~, as is relevant for the case that the weights are w = 1/sigma, with sigma known to be a reliable estimate of the uncertainty.€öfRaisesÙ¯‚€öhReceivesÙ¯‚€ögReturnsÙ¯‚ƒÙ°ƒapx)ndarray, shape (deg + 1,) or (deg + 1, K)Ù¹‚‡Ù§x2Polynomial coefficients, highest power first.  If Ù¢„ayÙ „ööelocalayelocalõÙ§x was 2-D, the coefficients for Ù£ƒakööÙ§t-th data set are in Ù¡fp[:,k]Ù§a.€Ù°ƒ`x'residuals, rank, singular_values, rcondƒÙ¹‚‚Ù§x"These values are only returned if Ù¡lfull == True€ÙÈ„Ù¹‚Ù§x>residuals -- sum of squared residuals of the least squares fit€ÙÁÙÅ‚Ù¹‚Ù§x4rank -- the effective rank of the scaled Vandermonde€Ù¹‚Ù§rcoefficient matrix€ÙÁÙÅ‚Ù¹‚Ù§x<singular_values -- singular values of the scaled Vandermonde€Ù¹‚Ù§rcoefficient matrix€Ù¹‚ƒÙ§rrcond -- value of Ù£ƒercondööÙ§a.€Ù¹‚ƒÙ§vFor more details, see Ù¢„rnumpy.linalg.lstsqÙ „enumpyf1.22.3fmodulernumpy.linalg.lstsqfmoduleõÙ§a.€Ù°ƒaVxndarray, shape (M,M) or (M,M,K)Ù¹‚ˆÙ§pPresent only if Ù¡mfull == FalseÙ§e and Ù¡kcov == TrueÙ§xÉ.  The covariance matrix of the polynomial coefficient estimates.  The diagonal of this matrix are the variance estimates for each coefficient.  If y is a 2-D array, then the covariance matrix for the Ù£ƒakööÙ§t-th data set are in Ù¡hV[:,:,k]€ögSummaryÙ¯‚Ù¹‚Ù§xLeast squares polynomial fit.€öhWarningsÙ¯‚€öeWarnsÙ¯‚Ù°ƒ`kRankWarningƒÙ¹‚ƒÙ§xhThe rank of the coefficient matrix in the least-squares fit is deficient. The warning is only raised if Ù¡mfull == FalseÙ§a.€Ù¹‚Ù§x!The warnings can be turned off by€ÙÀxG>>> import warnings
>>> warnings.simplefilter('ignore', np.RankWarning)öfYieldsÙ¯‚€ö‰gSummarypExtended SummaryjParametersgReturnseWarnshSee AlsoeNotesjReferenceshExampless/numpy/ma/extras.py_r<class 'function'>pnumpy.ma.polyfitÙ¯‚Ù´ƒ˜PÙ±‚bknfimportÙ±‚`a Ù±‚bnnhwarningsÙ±‚`a
Ù±‚`axÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`bnpÙ±‚aoa.Ù±‚`Ù¢„earrayÙ „enumpyf1.22.3fmoduleknumpy.arrayfmoduleõÙ±‚`a(Ù±‚`a[Ù±‚bmfc0.0Ù±‚`a,Ù±‚`a Ù±‚bmfc1.0Ù±‚`a,Ù±‚`a Ù±‚bmfc2.0Ù±‚`a,Ù±‚`a Ù±‚bmfc3.0Ù±‚`a,Ù±‚`b  Ù±‚bmfc4.0Ù±‚`a,Ù±‚`b  Ù±‚bmfc5.0Ù±‚`a]Ù±‚`a)Ù±‚`a
Ù±‚`ayÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`bnpÙ±‚aoa.Ù±‚`Ù¢„earrayÙ „enumpyf1.22.3fmoduleknumpy.arrayfmoduleõÙ±‚`a(Ù±‚`a[Ù±‚bmfc0.0Ù±‚`a,Ù±‚`a Ù±‚bmfc0.8Ù±‚`a,Ù±‚`a Ù±‚bmfc0.9Ù±‚`a,Ù±‚`a Ù±‚bmfc0.1Ù±‚`a,Ù±‚`a Ù±‚aoa-Ù±‚bmfc0.8Ù±‚`a,Ù±‚`a Ù±‚aoa-Ù±‚bmfc1.0Ù±‚`a]Ù±‚`a)Ù±‚`a
Ù±‚`azÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`bnpÙ±‚aoa.Ù±‚`Ù¢„gpolyfitÙ „enumpyf1.22.3fmodulemnumpy.polyfitfmoduleõÙ±‚`a(Ù±‚`axÙ±‚`a,Ù±‚`a Ù±‚`ayÙ±‚`a,Ù±‚`a Ù±‚bmia3Ù±‚`a)Ù±‚`a
Ù±‚`azxFarray([ 0.08703704, -0.81349206,  1.69312169, -0.03968254]) # may varyfexecedÙ¹‚ƒÙ§xIt is convenient to use Ù¢„fpoly1dÙ „enumpyf1.22.3fmodulelnumpy.poly1dfmoduleõÙ§x& objects for dealing with polynomials:€Ù´ƒÙ±‚`apÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`bnpÙ±‚aoa.Ù±‚`Ù¢„fpoly1dÙ „enumpyf1.22.3fmodulelnumpy.poly1dfmoduleõÙ±‚`a(Ù±‚`azÙ±‚`a)Ù±‚`a
Ù±‚`apÙ±‚`a(Ù±‚bmfc0.5Ù±‚`a)x0.6143849206349179 # may varyfexecedÙ´ƒ„Ù±‚`apÙ±‚`a(Ù±‚bmfc3.5Ù±‚`a)x-0.34732142857143039 # may varyfexecedÙ´ƒ„Ù±‚`apÙ±‚`a(Ù±‚bmib10Ù±‚`a)x22.579365079365115 # may varyfexecedÙ¹‚Ù§x,High-order polynomials may oscillate wildly:€Ù´ƒ˜.Ù±‚akdwithÙ±‚`a Ù±‚`hwarningsÙ±‚aoa.Ù±‚`ncatch_warningsÙ±‚`a(Ù±‚`a)Ù±‚`a:Ù±‚`a
Ù±‚`d    Ù±‚`hwarningsÙ±‚aoa.Ù±‚`lsimplefilterÙ±‚`a(Ù±‚bs1a'Ù±‚bs1fignoreÙ±‚bs1a'Ù±‚`a,Ù±‚`a Ù±‚`bnpÙ±‚aoa.Ù±‚`Ù¢„kRankWarningÙ „enumpyf1.22.3fmoduleqnumpy.RankWarningfmoduleõÙ±‚`a)Ù±‚`a
Ù±‚`d    Ù±‚`cp30Ù±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`bnpÙ±‚aoa.Ù±‚`Ù¢„fpoly1dÙ „enumpyf1.22.3fmodulelnumpy.poly1dfmoduleõÙ±‚`a(Ù±‚`bnpÙ±‚aoa.Ù±‚`Ù¢„gpolyfitÙ „enumpyf1.22.3fmodulemnumpy.polyfitfmoduleõÙ±‚`a(Ù±‚`axÙ±‚`a,Ù±‚`a Ù±‚`ayÙ±‚`a,Ù±‚`a Ù±‚bmib30Ù±‚`a)Ù±‚`a)c...fexecedÙ´ƒ„Ù±‚`cp30Ù±‚`a(Ù±‚bmia4Ù±‚`a)x-0.80000000000000204 # may varyfexecedÙ´ƒ„Ù±‚`cp30Ù±‚`a(Ù±‚bmiÙ¢„a5Ù „enumpyf1.22.3fmoduletnumpy.typing._256BitfmoduleõÙ±‚`a)x-0.99999999999999445 # may varyfexecedÙ´ƒ„Ù±‚`cp30Ù±‚`a(Ù±‚bmfc4.5Ù±‚`a)x-0.10547061179440398 # may varyfexecedÙ¹‚Ù§mIllustration:€Ù´ƒ˜TÙ±‚bknfimportÙ±‚`a Ù±‚bnnÙ¢„jmatplotlibÙ „jmatplotlibe3.5.1fmodulejmatplotlibfmoduleõÙ±‚bnna.Ù±‚bnnÙ¢„fpyplotÙ „jmatplotlibe3.5.1fmoduleqmatplotlib.pyplotfmoduleõÙ±‚`a Ù±‚akbasÙ±‚`a Ù±‚bnnÙ¢„cpltÙ „jmatplotlibe3.5.1fmoduleqmatplotlib.pyplotfmoduleõÙ±‚`a
Ù±‚`bxpÙ±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`bnpÙ±‚aoa.Ù±‚`Ù¢„hlinspaceÙ „enumpyf1.22.3fmodulennumpy.linspacefmoduleõÙ±‚`a(Ù±‚aoa-Ù±‚bmia2Ù±‚`a,Ù±‚`a Ù±‚bmia6Ù±‚`a,Ù±‚`a Ù±‚bmic100Ù±‚`a)Ù±‚`a
Ù±‚`a_Ù±‚`a Ù±‚aoa=Ù±‚`a Ù±‚`Ù¢„cpltÙ „jmatplotlibe3.5.1fmoduleqmatplotlib.pyplotfmoduleõÙ±‚aoa.Ù±‚`Ù¢„dplotÙ „jmatplotlibe3.5.1fmodulevmatplotlib.pyplot.plotfmoduleõÙ±‚`a(Ù±‚`axÙ±‚`a,Ù±‚`a Ù±‚`ayÙ±‚`a,Ù±‚`a Ù±‚bs1a'Ù±‚bs1a.Ù±‚bs1a'Ù±‚`a,Ù±‚`a Ù±‚`bxpÙ±‚`a,Ù±‚`a Ù±‚`apÙ±‚`a(Ù±‚`bxpÙ±‚`a)Ù±‚`a,Ù±‚`a Ù±‚bs1a'Ù±‚bs1a-Ù±‚bs1a'Ù±‚`a,Ù±‚`a Ù±‚`bxpÙ±‚`a,Ù±‚`a Ù±‚`cp30Ù±‚`a(Ù±‚`bxpÙ±‚`a)Ù±‚`a,Ù±‚`a Ù±‚bs1a'Ù±‚bs1b--Ù±‚bs1a'Ù±‚`a)Ù±‚`a
Ù±‚`Ù¢„cpltÙ „jmatplotlibe3.5.1fmoduleqmatplotlib.pyplotfmoduleõÙ±‚aoa.Ù±‚`Ù¢„dylimÙ „jmatplotlibe3.5.1fmodulevmatplotlib.pyplot.ylimfmoduleõÙ±‚`a(Ù±‚aoa-Ù±‚bmia2Ù±‚`a,Ù±‚bmia2Ù±‚`a)g(-2, 2)fexecedÙ´ƒ…Ù±‚`Ù¢„cpltÙ „jmatplotlibe3.5.1fmoduleqmatplotlib.pyplotfmoduleõÙ±‚aoa.Ù±‚`Ù¢„dshowÙ „jmatplotlibe3.5.1fmodulevmatplotlib.pyplot.showfmoduleõÙ±‚`a(Ù±‚`a)`fexecedÙ¸x!fig-numpy.ma.extras.polyfit-0.pngöƒÙ¼ƒÙ»ƒllinalg.lstsqrnumpy.linalg.lstsqõÙ¹‚Ù§xComputes a least-squares fit.€öÙ¼ƒÙ»ƒgpolyvalmnumpy.polyvalõÙ¹‚Ù§xCompute polynomial values.€öÙ¼ƒÙ»ƒx"scipy.interpolate.UnivariateSplineööÙ¹‚Ù§uComputes spline fits.€öf1.22.3Ù«x=polyfit(x, y, deg, rcond=None, full=False, w=None, cov=False)öwnumpy.ma.extras.polyfit€